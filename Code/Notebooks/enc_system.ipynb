{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "enc_system.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN85XPR2arO8znUfJp2ZDZf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erofale/encoderProject/blob/master/Code/Notebooks/enc_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6eGPk6quNpM"
      },
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "''' Класс нормировки данных '''\n",
        "class Normalizer():\n",
        "    \n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim : int\n",
        "        Размерность входных данных.\n",
        "    range_val_pairs : List[Tuple[float,float]]\n",
        "        Диапазон значений входных данных.\n",
        "    norm_min : float, optional\n",
        "        Нижняя граница нормированных данных (по умолчанию 0).\n",
        "    norm_max : float, optional\n",
        "        Верхняя граница нормированных данных (по умолчанию 1).\n",
        "    '''\n",
        "    def __init__(self, dim : int, range_val_pairs : List[Tuple[float,float]], norm_min : float = 0., norm_max : float = 1.):\n",
        "        self.dim = dim\n",
        "        self.range_val_pairs = range_val_pairs\n",
        "        self.range_val = [(i[1] - i[0]) for i in self.range_val_pairs]\n",
        "        self.norm_min = norm_min\n",
        "        self.norm_max = norm_max\n",
        "        self.range_norm = norm_max - norm_min\n",
        "    \n",
        "    \n",
        "    def __normire(self, entryVal : float, ind : int) -> float:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        entryVal : float\n",
        "            Входное значение для нормировки.\n",
        "        ind : int\n",
        "            Индекс элемента в массиве.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Нормированное значение.\n",
        "\n",
        "        '''\n",
        "        return self.norm_min + ((entryVal - self.range_val_pairs[ind][0]) * self.range_norm / self.range_val[ind])\n",
        "    \n",
        "    def __renormire(self, normVal : float, ind : int) -> float:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        normVal : float\n",
        "            Нормированное значение для денормировки.\n",
        "        ind : int\n",
        "            Индекс элемента в массиве.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Денормированное значение.\n",
        "        '''\n",
        "        return self.range_val_pairs[ind][0] + ((normVal - self.norm_min) / self.range_norm * self.range_val[ind])\n",
        "    \n",
        "    def normalize(self, data) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : list, array\n",
        "            Входной набор данных для нормировки.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Нормированный набор данных.\n",
        "        '''\n",
        "        count = 0\n",
        "        if type(data) == list:\n",
        "            count = len(data)\n",
        "        else:\n",
        "            count = data.shape[0]\n",
        "        normData = []\n",
        "        for i in range(count):\n",
        "            cur_sample = []\n",
        "            for j in range(self.dim):\n",
        "                cur_sample.append(self.__normire(data[i][j], j))\n",
        "            normData.append(cur_sample)\n",
        "        return normData\n",
        "    \n",
        "    def renormalize(self, normData) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        normData : list, array\n",
        "            Нормированный набор данных.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Денормированный набор данных.\n",
        "        '''\n",
        "        count = 0\n",
        "        if type(normData) == list:\n",
        "            count = len(normData)\n",
        "        else:\n",
        "            count = normData.shape[0]\n",
        "        data = []\n",
        "        for i in range(count):\n",
        "            cur_sample = []\n",
        "            for j in range(self.dim):\n",
        "                cur_sample.append(self.__renormire(normData[i][j], j))\n",
        "            data.append(cur_sample)\n",
        "        return data\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMyXmzKvuVfg"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "#!pip install git+https://github.com/naught101/sobol_seq@v0.2.0#egg=sobol_seq\n",
        "import sobol_seq\n",
        "import time\n",
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "''' Класс генерации данных '''\n",
        "class DataGenerator():\n",
        "\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim: int\n",
        "        Размерность входных данных.\n",
        "    val_range : List[Tuple[float,float]]\n",
        "        Диапазон значений входных данных.\n",
        "    '''\n",
        "    def __init__(self, dim : int, val_range : List[Tuple[float,float]]):\n",
        "        try:\n",
        "            assert dim  == len(val_range), 'Размерность входных диапазонов не равна входной размерности!'\n",
        "            self.dim = dim\n",
        "            self.val_range = val_range\n",
        "            random.seed(int(time.time()))\n",
        "        except AssertionError as e:\n",
        "            raise AssertionError(e.args[0])\n",
        "    \n",
        "\n",
        "    def get_random(self, samples_num : int, irrelevant_var_count : int = 0, write_in_file : bool = False) -> List[List[float]]:\n",
        "        '''\n",
        "        Рандомная генерация данных.\n",
        "        Parameters\n",
        "        ----------\n",
        "        samples_num : int\n",
        "            Количество записей.\n",
        "        irrelevant_var_count : int, optional\n",
        "            Количество незначащих переменных. По умолчанию 0.\n",
        "        write_in_file : bool, optional\n",
        "            Запись в файл. По умолчанию False.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        arr = []\n",
        "        for k in range(samples_num):\n",
        "            sample = []\n",
        "            # добавляем существенные переменные\n",
        "            for i in self.val_range:\n",
        "                sample.append(random.uniform(i[0], i[1]))\n",
        "            # добавляем несущественные переменные\n",
        "            if irrelevant_var_count != 0:\n",
        "                for i in range(irrelevant_var_count):\n",
        "                    sample.append(random.uniform(0., 1.))\n",
        "            arr.append(sample)\n",
        "        if write_in_file:\n",
        "            col = [('x' + str(i+1)) for i in range(self.dim + irrelevant_var_count)]\n",
        "            df = pd.DataFrame(arr, columns=col)\n",
        "            df.to_csv(f'../../DataSet/random_{self.dim}_{samples_num}_{irrelevant_var_count}.csv')\n",
        "        return arr\n",
        "    \n",
        "\n",
        "    def get_sobol(self, samples_num : int, irrelevant_var_count : int = 0, write_in_file : bool = False) -> List[List[float]]:\n",
        "        '''\n",
        "        Генерация данных от 0 до 1 методом Sobol.\n",
        "        Parameters\n",
        "        ----------\n",
        "        samples_num : int\n",
        "            Количество записей.\n",
        "        irrelevant_var_count : int, optional\n",
        "            Количество незначащих переменных. По умолчанию 0.\n",
        "        write_in_file : bool, optional\n",
        "            Запись в файл. По умолчанию False.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        arr = sobol_seq.i4_sobol_generate(self.dim, samples_num)\n",
        "        if irrelevant_var_count != 0:\n",
        "            zeros = [[0] for i in range(irrelevant_var_count)]\n",
        "            arr = np.insert(arr, obj=self.dim, values=zeros, axis=1)\n",
        "        if write_in_file:\n",
        "            col = [('x' + str(i+1)) for i in range(self.dim + irrelevant_var_count)]\n",
        "            df = pd.DataFrame(arr, columns=col)\n",
        "            df.to_csv(f'../DataSet/sobol_{self.dim}_{samples_num}_{irrelevant_var_count}.csv')\n",
        "        return list(arr)\n",
        "    \n",
        "    \n",
        "    def get_from_file(self, filename : str) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        filename : str\n",
        "            Имя файла.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        OSError\n",
        "            Файл не найден.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        try:\n",
        "            return list(pd.read_csv(filename, index_col=0).to_numpy('float32'))\n",
        "        except OSError as e:\n",
        "            raise OSError(e.args[0])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foZwblL7uYOt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from keras.layers import Lambda\n",
        "import numpy as np\n",
        "\n",
        "''' Класс автоэнкодеров '''\n",
        "class AutoencoderClass():\n",
        "  def __init__(self, func, input_dim : int, encoding_dim : int, activations : list, enc_type : str, normalizer : Normalizer):\n",
        "    self.func = func                 # Функция обучения\n",
        "    self.batch = 0\n",
        "    self.input_dim = input_dim       # Размерность входного представления\n",
        "    self.encoding_dim = encoding_dim # Размерность кодированного представления\n",
        "    self.activations = activations   # Функции активации\n",
        "    self.enc_type = enc_type         # Тип автоэнкодера\n",
        "    self.aes_types = {'dense': self.__create_dense_ae,\n",
        "                      'deep':  self.__create_deep_dense_ae,\n",
        "                      'conv':  self.__create_deep_conv_ae,\n",
        "                      'vae':   self.__create_vae}\n",
        "    self.normalizer = normalizer\n",
        "    try:\n",
        "      # Сборка моделей\n",
        "      self.encoder, self.decoder, self.autoencoder = self.aes_types[self.enc_type]()\n",
        "      self.autoencoder.compile(optimizer = 'adam', loss = self.custom_loss, metrics=['accuracy'])\n",
        "    except KeyError as e:\n",
        "      raise ValueError('Undefined unit: {}'.format(e.args[0]))\n",
        "\n",
        "  # Обучение модели\n",
        "  def fit(self, train_data, test_data, epochs : int, batch_size : int, shuffle : bool):\n",
        "    self.batch = batch_size\n",
        "    if self.enc_type != 'conv':\n",
        "      self.autoencoder.fit(train_data, train_data,\n",
        "                           epochs=epochs,\n",
        "                           batch_size=self.batch,\n",
        "                           shuffle=shuffle,\n",
        "                           validation_data=(test_data, test_data))\n",
        "    else:\n",
        "      grid_train = []\n",
        "      grid_test = []\n",
        "      for i in range(len(train_data)):\n",
        "        xx, yy = np.meshgrid(train_data[i], train_data[i])\n",
        "        grid_train.append(xx)\n",
        "\n",
        "      for i in range(len(test_data)):\n",
        "        xx, yy = np.meshgrid(test_data[i], test_data[i])\n",
        "        grid_test.append(xx)\n",
        "      \n",
        "      self.autoencoder.fit(grid_train, grid_train,\n",
        "                           epochs=epochs,\n",
        "                           batch_size=self.batch,\n",
        "                           shuffle=shuffle,\n",
        "                           validation_data=(grid_test, grid_test))\n",
        "\n",
        "  # Предсказание результата\n",
        "  def predict(self, x_vector):\n",
        "    if self.enc_type != 'conv':\n",
        "      return self.autoencoder.predict(x_vector)\n",
        "    else:\n",
        "      return self.autoencoder.predict(x_vector)[0]\n",
        "\n",
        "  # Тип автоэнкодера\n",
        "  def get_aec_type(self):\n",
        "    return self.enc_type\n",
        "\n",
        "  # Возвращает собранные модели\n",
        "  def get_models(self):\n",
        "    return self.autoencoder, self.encoder, self.decoder\n",
        "\n",
        "  # Loss функция\n",
        "  @tf.autograph.experimental.do_not_convert\n",
        "  def custom_loss(self, x_true, x_pred):\n",
        "    return K.mean(K.square(self.func(self.normalizer.renormalize([x_pred])[0]) - self.func(self.normalizer.renormalize([x_true])[0])))\n",
        "\n",
        "  ''' Сжимающий автоэнкодер '''\n",
        "  def __create_dense_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    encoded = Dense(self.encoding_dim, activation = self.activations[0])(input_data)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape = (self.encoding_dim))\n",
        "    decoded = Dense(self.input_dim, activation = self.activations[1])(input_encoded)\n",
        "\n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name = \"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name = \"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name = \"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Глубокий автоэнкодер '''\n",
        "  def __create_deep_dense_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    ############# Здесь фиксить надо с размерностями слоёв и как подавать активации на вход##########\n",
        "    x = Dense(self.encoding_dim*3, activation='relu')(input_data)\n",
        "    x = Dense(self.encoding_dim*2, activation='relu')(x)\n",
        "    encoded = Dense(self.encoding_dim, activation='linear')(x)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(self.encoding_dim,))\n",
        "    ############# Здесь фиксить надо с размерностями слоёв ##########\n",
        "    x = Dense(self.encoding_dim*2, activation='relu')(input_encoded)\n",
        "    x = Dense(self.encoding_dim*3, activation='relu')(x)\n",
        "    decoded = Dense(self.input_dim, activation='sigmoid')(x)\n",
        "    \n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Сверточный автоэнкодер '''\n",
        "  def __create_deep_conv_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim, self.input_dim, 1))\n",
        "    x = Conv2D(25, (2, 2), activation='relu', padding='same')(input_data)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    #x = Conv2D(32, (2, 2), activation='relu', padding='same')(x)\n",
        "    #x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    encoded = Conv2D(1, (2, 2), activation='relu', padding='same')(x)\n",
        "\n",
        "    # На этом моменте представление  (7, 7, 1) т.е. 49-размерное\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(7, 7, 1))\n",
        "    #x = Conv2D(32, (7, 7), activation='relu', padding='same')(input_encoded)\n",
        "    #x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(25, (2, 2), activation='relu', padding='same')(input_encoded)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    decoded = Conv2D(1, (2, 2), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Вариационный автоэнкодер                         '''\n",
        "  ''' Работает на основе девергенции Кульбака-Лейблера '''\n",
        "  ''' Идея: переход данных скрытого слоя к нормальному распределению'''\n",
        "  ''' Статья: https://habr.com/ru/post/484756/ '''\n",
        "  ''' Видео:  https://youtu.be/ebI3JLAcWqQ '''\n",
        "  def __create_vae(self):\n",
        "    hidden_dim = 2\n",
        "    \n",
        "    # Выключение нейронов во избежании переобучения\n",
        "    def dropout_and_batch(x):\n",
        "      return Dropout(0.3)(BatchNormalization()(x))\n",
        "\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    x = Dense(self.encoding_dim, activation='relu')(input_data)\n",
        "    x = dropout_and_batch(x)\n",
        "    #x = Dense(128, activation='relu')(x)\n",
        "    #x = dropout_and_batch(x)\n",
        "    \n",
        "    z_mean = Dense(self.encoding_dim)(x)    # Мат ожидание\n",
        "    z_log_var = Dense(self.encoding_dim)(x) # Логарифм дисперсии\n",
        "    \n",
        "    # Нормальное распределение N(0, 1)\n",
        "    def noiser(args):\n",
        "      global z_mean, z_log_var\n",
        "      z_mean, z_log_var = args\n",
        "      N = K.random_normal(shape=(self.batch, self.encoding_dim), mean=0., stddev=1.0)\n",
        "      return K.exp(z_log_var / 2) * N + z_mean\n",
        "    \n",
        "    # Преобразование данных в нормальное распределения\n",
        "    h = Lambda(noiser, output_shape=(self.encoding_dim))([z_mean, z_log_var])\n",
        "    \n",
        "    input_encoded = Input(shape=(self.encoding_dim))\n",
        "    d = Dense(self.encoding_dim, activation='relu')(input_encoded)\n",
        "    d = dropout_and_batch(d)\n",
        "    #d = Dense(256, activation='relu')(d)\n",
        "    #d = dropout_and_batch(d)\n",
        "    decoded = Dense(self.input_dim, activation='sigmoid')(d)\n",
        "    \n",
        "    encoder = Model(input_data, h, name='encoder')\n",
        "    decoder = Model(input_encoded, decoded, name='decoder')\n",
        "    vae = Model(input_data, decoder(encoder(input_data)), name=\"vae\")\n",
        "    return encoder, decoder, vae"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ndsDOjUubS-",
        "outputId": "9bdc7b84-971a-43c8-a3ba-d5466ba23555"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def func(x):\n",
        "  return x[0]*x[1] + x[1]*x[2] + x[3]*x[3]\n",
        "\n",
        "\n",
        "def compare(orig_data, pred_data):\n",
        "    # clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "    # scores_x = cross_val_score(clf, orig_data[0:10], pred_data[0:10], cv=5)\n",
        "    # scores_y = cross_val_score(clf, [func(x) for x in orig_data][0:10], [func(x) for x in pred_data][0:10], cv=5)\n",
        "    \n",
        "    y_error = mean_squared_error(orig_data, pred_data)\n",
        "    x_error = mean_squared_error([func(x) for x in orig_data], [func(x) for x in pred_data])\n",
        "    \n",
        "    print(f'Error X: {x_error:.2f}')\n",
        "    print(f'Error Y: {y_error:.2f}')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dim = 4\n",
        "    irr_dim = 2\n",
        "    data_range = [(0, 100), (0, 100), (0, 100), (0, 100)]\n",
        "    generator = DataGenerator(dim, data_range)\n",
        "    normalizer = Normalizer(dim, data_range)\n",
        "    \n",
        "    n = 30000\n",
        "    sobol_data = generator.get_sobol(n, irr_dim)\n",
        "    data_train = np.array(sobol_data[0:int(n * 0.7)])\n",
        "    data_test = np.array(sobol_data[int(n * 0.7):n])\n",
        "    \n",
        "    model = AutoencoderClass(func, dim + irr_dim, 4, list(['relu', 'sigmoid']), 'dense', normalizer)\n",
        "    model.fit(data_train, data_test, 30, 16, True)\n",
        "    \n",
        "    pred_data = normalizer.renormalize([model.predict(x.reshape(1,dim + irr_dim))[0] for x in sobol_data[0:100]])\n",
        "    compare(normalizer.renormalize(sobol_data)[0:100], pred_data[0:100])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 21642148.0000 - accuracy: 0.3061 - val_loss: 11262347.0000 - val_accuracy: 0.4117\n",
            "Epoch 2/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 13483430.0000 - accuracy: 0.5266 - val_loss: 8895773.0000 - val_accuracy: 0.5412\n",
            "Epoch 3/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 11558032.0000 - accuracy: 0.5299 - val_loss: 7880265.5000 - val_accuracy: 0.5207\n",
            "Epoch 4/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 10293317.0000 - accuracy: 0.5376 - val_loss: 6616661.0000 - val_accuracy: 0.5284\n",
            "Epoch 5/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 9438550.0000 - accuracy: 0.5517 - val_loss: 5621153.5000 - val_accuracy: 0.5549\n",
            "Epoch 6/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 8611608.0000 - accuracy: 0.5720 - val_loss: 4719421.0000 - val_accuracy: 0.5816\n",
            "Epoch 7/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 7076725.5000 - accuracy: 0.5972 - val_loss: 3713714.0000 - val_accuracy: 0.6226\n",
            "Epoch 8/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 6721469.5000 - accuracy: 0.6287 - val_loss: 3453836.7500 - val_accuracy: 0.6364\n",
            "Epoch 9/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 6154177.0000 - accuracy: 0.6454 - val_loss: 2952100.5000 - val_accuracy: 0.6624\n",
            "Epoch 10/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 5501172.5000 - accuracy: 0.6670 - val_loss: 2498514.2500 - val_accuracy: 0.6829\n",
            "Epoch 11/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 4796219.5000 - accuracy: 0.6799 - val_loss: 2180855.0000 - val_accuracy: 0.6938\n",
            "Epoch 12/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 4953264.0000 - accuracy: 0.6880 - val_loss: 2393148.2500 - val_accuracy: 0.6976\n",
            "Epoch 13/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 4337666.0000 - accuracy: 0.6977 - val_loss: 1958310.7500 - val_accuracy: 0.7062\n",
            "Epoch 14/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 4508431.5000 - accuracy: 0.7012 - val_loss: 2007344.2500 - val_accuracy: 0.7030\n",
            "Epoch 15/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 4089295.5000 - accuracy: 0.7084 - val_loss: 1959875.5000 - val_accuracy: 0.7140\n",
            "Epoch 16/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 4559948.0000 - accuracy: 0.7098 - val_loss: 2078702.8750 - val_accuracy: 0.7131\n",
            "Epoch 17/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 4218530.0000 - accuracy: 0.7121 - val_loss: 1957950.1250 - val_accuracy: 0.7159\n",
            "Epoch 18/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 3982084.7500 - accuracy: 0.7150 - val_loss: 2046062.3750 - val_accuracy: 0.7149\n",
            "Epoch 19/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 4062878.5000 - accuracy: 0.7157 - val_loss: 2342619.0000 - val_accuracy: 0.7189\n",
            "Epoch 20/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 4104916.7500 - accuracy: 0.7167 - val_loss: 1854953.7500 - val_accuracy: 0.7201\n",
            "Epoch 21/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 4020419.7500 - accuracy: 0.7193 - val_loss: 1897167.7500 - val_accuracy: 0.7198\n",
            "Epoch 22/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 4403541.0000 - accuracy: 0.7190 - val_loss: 2056324.6250 - val_accuracy: 0.7186\n",
            "Epoch 23/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 4055365.7500 - accuracy: 0.7191 - val_loss: 2077690.2500 - val_accuracy: 0.7213\n",
            "Epoch 24/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 4233544.0000 - accuracy: 0.7187 - val_loss: 2206200.0000 - val_accuracy: 0.7194\n",
            "Epoch 25/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 4018458.7500 - accuracy: 0.7216 - val_loss: 1788817.1250 - val_accuracy: 0.7226\n",
            "Epoch 26/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 3889006.5000 - accuracy: 0.7229 - val_loss: 2014524.1250 - val_accuracy: 0.7182\n",
            "Epoch 27/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 3937817.2500 - accuracy: 0.7245 - val_loss: 2043993.0000 - val_accuracy: 0.7222\n",
            "Epoch 28/30\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 3978704.5000 - accuracy: 0.7240 - val_loss: 2432438.0000 - val_accuracy: 0.7233\n",
            "Epoch 29/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 3599855.5000 - accuracy: 0.7255 - val_loss: 1945610.2500 - val_accuracy: 0.7251\n",
            "Epoch 30/30\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 3712577.7500 - accuracy: 0.7266 - val_loss: 2023044.6250 - val_accuracy: 0.7221\n",
            "Error X: 3404758.29\n",
            "Error Y: 209.29\n"
          ]
        }
      ]
    }
  ]
}