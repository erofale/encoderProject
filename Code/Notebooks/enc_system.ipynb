{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "enc_system.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erofale/encoderProject/blob/master/Code/Notebooks/enc_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6eGPk6quNpM"
      },
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "''' Класс нормировки данных '''\n",
        "class Normalizer():\n",
        "    \n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim : int\n",
        "        Размерность входных данных.\n",
        "    irr_dim : int\n",
        "        Количество незначащих переменных.\n",
        "    range_val_pairs : List[Tuple[float,float]]\n",
        "        Диапазон значений входных данных.\n",
        "    norm_min : float, optional\n",
        "        Нижняя граница нормированных данных (по умолчанию 0).\n",
        "    norm_max : float, optional\n",
        "        Верхняя граница нормированных данных (по умолчанию 1).\n",
        "    '''\n",
        "    def __init__(self, dim : int, irr_dim : int, range_val_pairs : List[Tuple[float,float]], norm_min : float = 0., norm_max : float = 1.):\n",
        "        self.dim = dim\n",
        "        self.irr_dim = irr_dim\n",
        "        self.range_val_pairs = range_val_pairs\n",
        "        self.range_val = [(i[1] - i[0]) for i in self.range_val_pairs]\n",
        "        self.norm_min = norm_min\n",
        "        self.norm_max = norm_max\n",
        "        self.range_norm = norm_max - norm_min\n",
        "    \n",
        "    \n",
        "    def __normire(self, entryVal : float, ind : int) -> float:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        entryVal : float\n",
        "            Входное значение для нормировки.\n",
        "        ind : int\n",
        "            Индекс элемента в массиве.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Нормированное значение.\n",
        "\n",
        "        '''\n",
        "        return self.norm_min + ((entryVal - self.range_val_pairs[ind][0]) * self.range_norm / self.range_val[ind])\n",
        "    \n",
        "    def __renormire(self, normVal : float, ind : int) -> float:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        normVal : float\n",
        "            Нормированное значение для денормировки.\n",
        "        ind : int\n",
        "            Индекс элемента в массиве.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Денормированное значение.\n",
        "        '''\n",
        "        return self.range_val_pairs[ind][0] + ((normVal - self.norm_min) / self.range_norm * self.range_val[ind])\n",
        "    \n",
        "    def normalize(self, data) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : list, array\n",
        "            Входной набор данных для нормировки.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Нормированный набор данных.\n",
        "        '''\n",
        "        count = 0\n",
        "        if type(data) == list: \n",
        "          count = len(data)\n",
        "        else:\n",
        "          count = data.shape[0]\n",
        "        normData = []\n",
        "        for i in range(count):\n",
        "            cur_sample = []\n",
        "            for j in range(self.dim):\n",
        "                cur_sample.append(self.__normire(data[i][j], j))\n",
        "            for j in range(self.dim, self.dim + self.irr_dim):\n",
        "                cur_sample.append(data[i][j])\n",
        "            normData.append(cur_sample)\n",
        "        return normData\n",
        "    \n",
        "    def renormalize(self, normData) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        normData : list, array\n",
        "            Нормированный набор данных.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Денормированный набор данных.\n",
        "        '''\n",
        "        count = 0\n",
        "        if type(normData) == list: \n",
        "          count = len(normData)\n",
        "        else:\n",
        "          count = normData.shape[0]\n",
        "        data = []\n",
        "        for i in range(count):\n",
        "            cur_sample = []\n",
        "            for j in range(self.dim):\n",
        "                cur_sample.append(self.__renormire(normData[i][j], j))\n",
        "            for j in range(self.dim, self.dim + self.irr_dim):\n",
        "                cur_sample.append(normData[i][j])\n",
        "            data.append(cur_sample)\n",
        "        return data\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMyXmzKvuVfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d36415-66bb-4c56-e0f9-49d23f7a0075"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "!pip install git+https://github.com/naught101/sobol_seq@v0.2.0#egg=sobol_seq\n",
        "import sobol_seq\n",
        "import time\n",
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "''' Класс генерации данных '''\n",
        "class DataGenerator():\n",
        "\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim: int\n",
        "        Размерность входных данных.\n",
        "    val_range : List[Tuple[float,float]]\n",
        "        Диапазон значений входных данных.\n",
        "    '''\n",
        "    def __init__(self, dim : int, val_range : List[Tuple[float,float]]):\n",
        "        try:\n",
        "            assert dim  == len(val_range), 'Размерность входных диапазонов не равна входной размерности!'\n",
        "            self.dim = dim\n",
        "            self.val_range = val_range\n",
        "            random.seed(int(time.time()))\n",
        "        except AssertionError as e:\n",
        "            raise AssertionError(e.args[0])\n",
        "    \n",
        "\n",
        "    def get_random(self, samples_num : int, irrelevant_var_count : int = 0, write_in_file : bool = False) -> List[List[float]]:\n",
        "        '''\n",
        "        Рандомная генерация данных.\n",
        "        Parameters\n",
        "        ----------\n",
        "        samples_num : int\n",
        "            Количество записей.\n",
        "        irrelevant_var_count : int, optional\n",
        "            Количество незначащих переменных. По умолчанию 0.\n",
        "        write_in_file : bool, optional\n",
        "            Запись в файл. По умолчанию False.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        arr = []\n",
        "        for k in range(samples_num):\n",
        "            sample = []\n",
        "            # добавляем существенные переменные\n",
        "            for i in self.val_range:\n",
        "                sample.append(random.uniform(i[0], i[1]))\n",
        "            # добавляем несущественные переменные\n",
        "            if irrelevant_var_count != 0:\n",
        "                for i in range(irrelevant_var_count):\n",
        "                    sample.append(random.uniform(0., 1.))\n",
        "            arr.append(sample)\n",
        "        if write_in_file:\n",
        "            col = [('x' + str(i+1)) for i in range(self.dim + irrelevant_var_count)]\n",
        "            df = pd.DataFrame(arr, columns=col)\n",
        "            df.to_csv(f'../../DataSet/random_{self.dim}_{samples_num}_{irrelevant_var_count}.csv')\n",
        "        return arr\n",
        "    \n",
        "\n",
        "    def get_sobol(self, samples_num : int, irrelevant_var_count : int = 0, write_in_file : bool = False) -> List[List[float]]:\n",
        "        '''\n",
        "        Генерация данных от 0 до 1 методом Sobol.\n",
        "        Parameters\n",
        "        ----------\n",
        "        samples_num : int\n",
        "            Количество записей.\n",
        "        irrelevant_var_count : int, optional\n",
        "            Количество незначащих переменных. По умолчанию 0.\n",
        "        write_in_file : bool, optional\n",
        "            Запись в файл. По умолчанию False.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        arr = sobol_seq.i4_sobol_generate(self.dim, samples_num)\n",
        "        if irrelevant_var_count != 0:\n",
        "            zeros = [[0] for i in range(irrelevant_var_count)]\n",
        "            arr = np.insert(arr, obj=self.dim, values=zeros, axis=1)\n",
        "        if write_in_file:\n",
        "            col = [('x' + str(i+1)) for i in range(self.dim + irrelevant_var_count)]\n",
        "            df = pd.DataFrame(arr, columns=col)\n",
        "            df.to_csv(f'../DataSet/sobol_{self.dim}_{samples_num}_{irrelevant_var_count}.csv')\n",
        "        return list(arr)\n",
        "    \n",
        "    \n",
        "    def get_from_file(self, filename : str) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        filename : str\n",
        "            Имя файла.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        OSError\n",
        "            Файл не найден.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        try:\n",
        "            return list(pd.read_csv(filename, index_col=0).to_numpy('float32'))\n",
        "        except OSError as e:\n",
        "            raise OSError(e.args[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sobol_seq\n",
            "  Cloning https://github.com/naught101/sobol_seq (to revision v0.2.0) to /tmp/pip-install-hzgu59b2/sobol-seq_e5d45ddd92ab4a70ab4282e12105dcbf\n",
            "  Running command git clone -q https://github.com/naught101/sobol_seq /tmp/pip-install-hzgu59b2/sobol-seq_e5d45ddd92ab4a70ab4282e12105dcbf\n",
            "  Running command git checkout -q 8f819b68f64e1fea4999f5c64b73823a019fb244\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sobol_seq) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sobol_seq) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foZwblL7uYOt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from keras.layers import Lambda\n",
        "import numpy as np\n",
        "\n",
        "''' Класс автоэнкодеров '''\n",
        "class AutoencoderClass():\n",
        "  def __init__(self, func, input_dim : int, encoding_dim : int, activations : list, enc_type : str, normalizer : Normalizer):\n",
        "    self.func = func                 # Функция обучения\n",
        "    self.batch = 0                   # Размр батча\n",
        "    self.input_dim = input_dim       # Размерность входного представления\n",
        "    self.encoding_dim = encoding_dim # Размерность кодированного представления\n",
        "    self.activations = activations   # Функции активации\n",
        "    self.enc_type = enc_type         # Тип автоэнкодера\n",
        "    self.aes_types = {'dense': self.__create_dense_ae,\n",
        "                      'deep':  self.__create_deep_dense_ae,\n",
        "                      'conv':  self.__create_deep_conv_ae,\n",
        "                      'vae':   self.__create_vae}\n",
        "    self.normalizer = normalizer\n",
        "    try:\n",
        "      # Сборка моделей\n",
        "      self.encoder, self.decoder, self.autoencoder = self.aes_types[self.enc_type]()\n",
        "      if self.aes_types != 'vae':\n",
        "        self.autoencoder.compile(optimizer = 'adam', loss = self.custom_loss, metrics=['accuracy'])\n",
        "      else:\n",
        "        self.autoencoder.compile(optimizer = 'adam', loss = self.vae_loss, metrics=['accuracy'])\n",
        "    except KeyError as e:\n",
        "      raise ValueError('Undefined unit: {}'.format(e.args[0]))\n",
        "\n",
        "  # Обучение модели\n",
        "  def fit(self, train_data, test_data, epochs : int, batch_size : int, shuffle : bool):\n",
        "    self.batch = batch_size\n",
        "    if self.enc_type != 'conv':\n",
        "      self.autoencoder.fit(train_data, train_data,\n",
        "                           epochs=epochs,\n",
        "                           batch_size=self.batch,\n",
        "                           shuffle=shuffle,\n",
        "                           validation_data=(test_data, test_data))\n",
        "    else:\n",
        "      grid_train = []\n",
        "      grid_test = []\n",
        "      for i in range(len(train_data)):\n",
        "        xx, yy = np.meshgrid(train_data[i], train_data[i])\n",
        "        grid_train.append(xx)\n",
        "\n",
        "      for i in range(len(test_data)):\n",
        "        xx, yy = np.meshgrid(test_data[i], test_data[i])\n",
        "        grid_test.append(xx)\n",
        "      \n",
        "      self.autoencoder.fit(grid_train, grid_train,\n",
        "                           epochs=epochs,\n",
        "                           batch_size=self.batch,\n",
        "                           shuffle=shuffle,\n",
        "                           validation_data=(grid_test, grid_test))\n",
        "\n",
        "  # Предсказание результата\n",
        "  def predict(self, x_vector):\n",
        "    if self.enc_type != 'conv':\n",
        "      return self.autoencoder.predict(x_vector)\n",
        "    else:\n",
        "      return self.autoencoder.predict(x_vector)[0]\n",
        "\n",
        "  # Тип автоэнкодера\n",
        "  def get_aec_type(self):\n",
        "    return self.enc_type\n",
        "\n",
        "  # Возвращает собранные модели\n",
        "  def get_models(self):\n",
        "    return self.autoencoder, self.encoder, self.decoder\n",
        "\n",
        "  # Loss функция\n",
        "  @tf.autograph.experimental.do_not_convert\n",
        "  def custom_loss(self, x_true, x_pred):\n",
        "    return K.mean(K.abs(self.func(self.normalizer.renormalize(x_pred)[0]) - self.func(self.normalizer.renormalize(x_true)[0])))\n",
        "\n",
        "  # Loss функция для вариационного автоэнкодера\n",
        "  @tf.autograph.experimental.do_not_convert\n",
        "  def vae_loss(self, x_true, x_pred):\n",
        "    x_true = K.reshape(x_true, shape=(batch_size, self.input_dim))\n",
        "    x_pred = K.reshape(x_pred, shape=(batch_size, self.input_dim))\n",
        "    loss = self.custom_loss(x_true, x_pred)\n",
        "    kl_loss = -0.5 * K.sum(1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var))\n",
        "    return loss + kl_loss\n",
        "\n",
        "  ''' Сжимающий автоэнкодер '''\n",
        "  def __create_dense_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    encoded = Dense(self.encoding_dim, activation = self.activations[0])(input_data)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape = (self.encoding_dim))\n",
        "    decoded = Dense(self.input_dim, activation = self.activations[1])(input_encoded)\n",
        "\n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name = \"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name = \"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name = \"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Глубокий автоэнкодер '''\n",
        "  def __create_deep_dense_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    x = Dense(self.encoding_dim*2, activation='relu')(input_data)\n",
        "    encoded = Dense(self.encoding_dim, activation='linear')(x)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(self.encoding_dim,))\n",
        "    x = Dense(self.encoding_dim*2, activation='relu')(input_encoded)\n",
        "    decoded = Dense(self.input_dim, activation='sigmoid')(x)\n",
        "    \n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Сверточный автоэнкодер '''\n",
        "  def __create_deep_conv_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim, self.input_dim, 1))\n",
        "    x = Conv2D(25, (2, 2), activation='relu', padding='same')(input_data)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    #x = Conv2D(32, (2, 2), activation='relu', padding='same')(x)\n",
        "    #x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    encoded = Conv2D(1, (2, 2), activation='relu', padding='same')(x)\n",
        "\n",
        "    # На этом моменте представление  (7, 7, 1) т.е. 49-размерное\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(7, 7, 1))\n",
        "    #x = Conv2D(32, (7, 7), activation='relu', padding='same')(input_encoded)\n",
        "    #x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(25, (2, 2), activation='relu', padding='same')(input_encoded)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    decoded = Conv2D(1, (2, 2), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Вариационный автоэнкодер                         '''\n",
        "  ''' Работает на основе девергенции Кульбака-Лейблера '''\n",
        "  ''' Идея: переход данных скрытого слоя к нормальному распределению'''\n",
        "  ''' Статья: https://habr.com/ru/post/484756/ '''\n",
        "  ''' Видео:  https://youtu.be/ebI3JLAcWqQ '''\n",
        "  def __create_vae(self):\n",
        "    hidden_dim = 2\n",
        "\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    x = Dense(self.encoding_dim, activation='relu')(input_data)\n",
        "    \n",
        "    self.z_mean = Dense(self.encoding_dim)(x)    # Мат ожидание\n",
        "    self.z_log_var = Dense(self.encoding_dim)(x) # Логарифм дисперсии\n",
        "    \n",
        "    # Нормальное распределение N(0, 1)\n",
        "    def noiser(args):\n",
        "      self.z_mean, self.z_log_var = args\n",
        "      N = K.random_normal(shape=(self.batch, self.encoding_dim), mean=0., stddev=1.0)\n",
        "      return K.exp(self.z_log_var / 2) * N + self.z_mean\n",
        "    \n",
        "    # Преобразование данных в нормальное распределения\n",
        "    h = Lambda(noiser, output_shape=(self.encoding_dim,))([self.z_mean, self.z_log_var])\n",
        "    \n",
        "    input_encoded = Input(shape=(self.encoding_dim,))\n",
        "    d = Dense(self.encoding_dim, activation='relu')(input_encoded)\n",
        "    decoded = Dense(self.input_dim, activation='sigmoid')(d)\n",
        "    \n",
        "    encoder = Model(input_data, h, name='encoder')\n",
        "    decoder = Model(input_encoded, decoded, name='decoder')\n",
        "    vae = Model(input_data, decoder(encoder(input_data)), name=\"vae\")\n",
        "    return encoder, decoder, vae"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJFa6Av_hMvs"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def func(x):\n",
        "  return tf.math.sin(x[0]) + tf.math.sin(x[1]) + tf.math.sin(x[2]) + tf.math.sin(x[3]) + tf.math.sin(x[4]) + tf.math.sin(x[5])\n",
        "\n",
        "def disp_res(orig_x, orig_y, pred_x, pred_y):\n",
        "  n = len(orig_x)\n",
        "  for i in range(n):\n",
        "    print(f'Orig X: {orig_x[i]}')\n",
        "    print(f'Orig Y: {orig_y[i]}')\n",
        "    print(f'Pred X: {pred_x[i]}')\n",
        "    print(f'Pred Y: {pred_y[i]}\\n')\n",
        "\n",
        "\n",
        "def compare(orig_data, pred_data):\n",
        "  # clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "  # scores_x = cross_val_score(clf, orig_data[0:10], pred_data[0:10], cv=5)\n",
        "  # scores_y = cross_val_score(clf, [func(x) for x in orig_data][0:10], [func(x) for x in pred_data][0:10], cv=5)\n",
        "  y_orig = [func(x) for x in orig_data]\n",
        "  y_pred = [func(x) for x in pred_data]\n",
        "  k = 10\n",
        "  disp_res(orig_data[0:k], y_orig[0:k], pred_data[0:k], y_pred[0:k])\n",
        "\n",
        "  x_error = mean_absolute_error(orig_data, pred_data)\n",
        "  y_error = mean_absolute_error(y_orig, y_pred)\n",
        "\n",
        "  print(f'Abs error X: {x_error:.2f}')\n",
        "  print(f'Abs error Y: {y_error:.2f}')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DtsiTontXlf"
      },
      "source": [
        " #данные, тип автоэнкодера, шаг эпох, шаг батчей, шаг размерности, исходная размерность, размерность незначимых, шаг разбиения на выборку, количество точек\n",
        "import sys\n",
        "from numpy import arange\n",
        "def searchOpt(sobol_data ,enc_type : str, h_epoch : int, h_batch : int, h_size : int, dim : int, irr_dim : int, h_percent : float, n : int):\n",
        "  error = sys.float_info.max\n",
        "  hp_list = list()\n",
        "  for epoch in range(5, 60, h_epoch):\n",
        "    for batch in range(4, 256, h_batch):\n",
        "      for size in range(dim // 2, dim ,h_size):\n",
        "        for percent in arange(0.5, 1.0, h_percent):\n",
        "            data_train = np.array(sobol_data[0:int(n * h_percent)])\n",
        "            data_test = np.array(sobol_data[int(n * h_percent):n])\n",
        "            model = AutoencoderClass(func, dim + irr_dim, size, list(['relu', 'sigmoid']), enc_type, normalizer)\n",
        "            model.fit(data_train, data_test, epoch, batch, True)\n",
        "            rand_data = generator.get_random(100)\n",
        "            pred_data = normalizer.renormalize([model.predict(np.array(x).reshape(1,dim + irr_dim))[0] for x in normalizer.normalize(rand_data)])\n",
        "            if error > compare(rand_data, pred_data):\n",
        "              error = compare(rand_data, pred_data)\n",
        "              hp_list.clear()\n",
        "              hp_list.append(enc_type)\n",
        "              hp_list.append(epoch)\n",
        "              hp_list.append(batch)\n",
        "              hp_list.append(size)\n",
        "              hp_list.append(percent)\n",
        "  return hp_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ndsDOjUubS-",
        "outputId": "d37e5665-7d13-4e5d-8b19-044fd8a9d4d8"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  dim = 6\n",
        "  irr_dim = 2\n",
        "  data_range = [(0, 100), (0, 100), (0, 100), (0, 100), (0, 100), (0, 100)]\n",
        "  generator = DataGenerator(dim, data_range)\n",
        "  normalizer = Normalizer(dim, irr_dim, data_range)\n",
        "\n",
        "  n = 20000\n",
        "  sobol_data = generator.get_sobol(n, irr_dim)\n",
        "  random.shuffle(sobol_data)\n",
        "  data_train = np.array(sobol_data[0:int(n * 0.8)])\n",
        "  data_test = np.array(sobol_data[int(n * 0.8):n])\n",
        "\n",
        "  model = AutoencoderClass(func, dim + irr_dim, 5, list(['relu', 'sigmoid']), 'vae', normalizer)\n",
        "  model.fit(data_train, data_test, 15, 50, True)\n",
        "\n",
        "  rand_data = generator.get_random(100, irr_dim)\n",
        "  pred_data = normalizer.renormalize([model.predict(np.array(x).reshape(1,dim + irr_dim))[0] for x in normalizer.normalize(rand_data)])\n",
        "  #pred_data = normalizer.renormalize([model.predict(x.reshape(1,dim + irr_dim))[0] for x in sobol_data[0:100]])\n",
        "  #compare(normalizer.renormalize(sobol_data)[0:100], pred_data[0:100])\n",
        "  #searchOpt(sobol_data, 'vae', 2, 8, 1, dim, irr_dim, 0.1, n)\n",
        "  compare(rand_data, pred_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "320/320 [==============================] - 24s 26ms/step - loss: 1.8585 - accuracy: 0.0024 - val_loss: 2.1115 - val_accuracy: 0.0030\n",
            "Epoch 2/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8842 - accuracy: 0.0027 - val_loss: 2.2615 - val_accuracy: 0.0033\n",
            "Epoch 3/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7932 - accuracy: 0.0034 - val_loss: 1.7440 - val_accuracy: 0.0043\n",
            "Epoch 4/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8754 - accuracy: 0.0063 - val_loss: 1.9769 - val_accuracy: 0.0052\n",
            "Epoch 5/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8002 - accuracy: 0.0066 - val_loss: 1.8587 - val_accuracy: 0.0082\n",
            "Epoch 6/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8770 - accuracy: 0.0086 - val_loss: 1.9696 - val_accuracy: 0.0122\n",
            "Epoch 7/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8144 - accuracy: 0.0094 - val_loss: 1.7676 - val_accuracy: 0.0090\n",
            "Epoch 8/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8426 - accuracy: 0.0143 - val_loss: 1.8494 - val_accuracy: 0.0198\n",
            "Epoch 9/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8672 - accuracy: 0.0161 - val_loss: 1.9798 - val_accuracy: 0.0180\n",
            "Epoch 10/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7765 - accuracy: 0.0182 - val_loss: 1.7064 - val_accuracy: 0.0170\n",
            "Epoch 11/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7457 - accuracy: 0.0208 - val_loss: 1.7661 - val_accuracy: 0.0272\n",
            "Epoch 12/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7563 - accuracy: 0.0253 - val_loss: 1.5964 - val_accuracy: 0.0215\n",
            "Epoch 13/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8197 - accuracy: 0.0213 - val_loss: 1.7251 - val_accuracy: 0.0207\n",
            "Epoch 14/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6781 - accuracy: 0.0228 - val_loss: 1.8647 - val_accuracy: 0.0245\n",
            "Epoch 15/15\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7221 - accuracy: 0.0260 - val_loss: 1.7296 - val_accuracy: 0.0227\n",
            "Orig X: [50.01071789810515, 70.47034930799603, 1.493731043900326, 45.11502648767638, 42.801613248720884, 35.98324610145185, 0.6427675639984005, 0.07715130990565544]\n",
            "Orig Y: 0.7131008505821228\n",
            "Pred X: [42.704737186431885, 53.15024256706238, 47.45451509952545, 52.485328912734985, 47.64760732650757, 48.14891815185547, 0.5752476, 0.4623331]\n",
            "Pred Y: -1.586103115518481\n",
            "\n",
            "Orig X: [39.9440151790732, 75.97817908635083, 49.26051026606447, 96.95630927598519, 30.6153333507853, 97.46152121686413, 0.0254114168419336, 0.36745446957529593]\n",
            "Orig Y: 0.1149006262421608\n",
            "Pred X: [39.735543727874756, 39.4637793302536, 44.32510435581207, 42.55892634391785, 48.9901065826416, 45.05798816680908, 0.62269044, 0.4934908]\n",
            "Pred Y: 1.1450207804662265\n",
            "\n",
            "Orig X: [30.731491021460233, 13.21176452216617, 75.88416785932863, 91.09375370994962, 45.44870305117368, 34.83210289366174, 0.6777771296971682, 0.20103648266237584]\n",
            "Orig Y: 1.1721689701080322\n",
            "Pred X: [40.0858610868454, 40.6379371881485, 48.52202534675598, 41.72169268131256, 50.53626894950867, 43.85969042778015, 0.59519494, 0.5361297]\n",
            "Pred Y: -0.7247543350083614\n",
            "\n",
            "Orig X: [99.5590207690761, 72.47750886917491, 87.64202257686537, 96.18886045522245, 83.11435287359089, 98.54200060109626, 0.35085520188078123, 0.9096086532993963]\n",
            "Orig Y: -0.3531728982925415\n",
            "Pred X: [50.24034380912781, 48.1602668762207, 45.335984230041504, 51.838093996047974, 48.775649070739746, 50.60080885887146, 0.53025895, 0.487478]\n",
            "Pred Y: 0.4231751167253153\n",
            "\n",
            "Orig X: [11.754818049749183, 17.45230423960429, 49.28425665578933, 27.23460688807088, 97.18812551924117, 12.167289670508419, 0.7673589946830941, 0.6745854161376196]\n",
            "Orig Y: -1.8679306507110596\n",
            "Pred X: [53.123605251312256, 42.8301215171814, 39.80977535247803, 54.92628216743469, 45.67772448062897, 50.35452842712402, 0.57695705, 0.46797433]\n",
            "Pred Y: 0.3063175425045067\n",
            "\n",
            "Orig X: [31.69631318163997, 48.03800728813125, 16.361499222994023, 89.4546201829939, 46.20204072412005, 38.05890240949689, 0.0771687065605281, 0.26601282138970284]\n",
            "Orig Y: 1.022244930267334\n",
            "Pred X: [28.716373443603516, 57.2529137134552, 43.48081350326538, 59.442490339279175, 39.43897485733032, 41.240715980529785, 0.7533172, 0.36455715]\n",
            "Pred Y: 0.5805045094576244\n",
            "\n",
            "Orig X: [48.89653138562105, 74.45900621435251, 39.20189287050988, 84.23271189750938, 86.6482756935943, 83.02768277577022, 0.8820169036604306, 0.08015852723440797]\n",
            "Orig Y: -0.22539925575256348\n",
            "Pred X: [46.15467190742493, 52.21012234687805, 48.36367666721344, 50.88106393814087, 49.54710900783539, 49.73812997341156, 0.5296066, 0.48525143]\n",
            "Pred Y: 0.2256842929033238\n",
            "\n",
            "Orig X: [12.979787700753874, 51.4443053379092, 45.68660772908635, 62.86417785625059, 18.179077458843594, 22.41091730894047, 0.9493180426074889, 0.45988237558615874]\n",
            "Orig Y: 1.3204067945480347\n",
            "Pred X: [34.55760478973389, 54.693031311035156, 44.15796399116516, 57.14169144630432, 42.23664104938507, 43.99532377719879, 0.69340163, 0.40047324]\n",
            "Pred Y: -1.1978811446908868\n",
            "\n",
            "Orig X: [7.127897361438251, 21.929854232373803, 23.701499818803708, 38.33021491915144, 17.529755196887653, 56.26176160722907, 0.4393888002575598, 0.3815181447873216]\n",
            "Orig Y: -0.8428580164909363\n",
            "Pred X: [48.390671610832214, 51.60585045814514, 48.94781708717346, 49.850231409072876, 50.76730251312256, 50.75861215591431, 0.5, 0.5]\n",
            "Pred Y: -0.39771947699213595\n",
            "\n",
            "Orig X: [81.83916814387733, 65.43705077737307, 65.8868981629383, 40.979067027117175, 94.55814698084613, 50.43899530389181, 0.8267014878831851, 0.5530606694300572]\n",
            "Orig Y: 1.0947051048278809\n",
            "Pred X: [37.122783064842224, 54.71223592758179, 45.94288766384125, 55.146825313568115, 44.49869394302368, 45.50942778587341, 0.6482272, 0.42452368]\n",
            "Pred Y: -0.07785240404329585\n",
            "\n",
            "Abs error X: 19.25\n",
            "Abs error Y: 1.70\n"
          ]
        }
      ]
    }
  ]
}