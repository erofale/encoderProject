{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "enc_system.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0cDQ7cQInTApJq6rK29I1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erofale/encoderProject/blob/master/Code/Notebooks/enc_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6eGPk6quNpM"
      },
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "''' Класс нормировки данных '''\n",
        "class Normalizer():\n",
        "    \n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim : int\n",
        "        Размерность входных данных.\n",
        "    range_val_pairs : List[Tuple[float,float]]\n",
        "        Диапазон значений входных данных.\n",
        "    norm_min : float, optional\n",
        "        Нижняя граница нормированных данных (по умолчанию 0).\n",
        "    norm_max : float, optional\n",
        "        Верхняя граница нормированных данных (по умолчанию 1).\n",
        "    '''\n",
        "    def __init__(self, dim : int, range_val_pairs : List[Tuple[float,float]], norm_min : float = 0., norm_max : float = 1.):\n",
        "        self.dim = dim\n",
        "        self.range_val_pairs = range_val_pairs\n",
        "        self.range_val = [(i[1] - i[0]) for i in self.range_val_pairs]\n",
        "        self.norm_min = norm_min\n",
        "        self.norm_max = norm_max\n",
        "        self.range_norm = norm_max - norm_min\n",
        "    \n",
        "    \n",
        "    def __normire(self, entryVal : float, ind : int) -> float:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        entryVal : float\n",
        "            Входное значение для нормировки.\n",
        "        ind : int\n",
        "            Индекс элемента в массиве.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Нормированное значение.\n",
        "\n",
        "        '''\n",
        "        return self.norm_min + ((entryVal - self.range_val_pairs[ind][0]) * self.range_norm / self.range_val[ind])\n",
        "    \n",
        "    def __renormire(self, normVal : float, ind : int) -> float:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        normVal : float\n",
        "            Нормированное значение для денормировки.\n",
        "        ind : int\n",
        "            Индекс элемента в массиве.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Денормированное значение.\n",
        "        '''\n",
        "        return self.range_val_pairs[ind][0] + ((normVal - self.norm_min) / self.range_norm * self.range_val[ind])\n",
        "    \n",
        "    def normalize(self, data) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : list, array\n",
        "            Входной набор данных для нормировки.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Нормированный набор данных.\n",
        "        '''\n",
        "        count = 0\n",
        "        if type(data) == list:\n",
        "            count = len(data)\n",
        "        else:\n",
        "            count = data.shape[0]\n",
        "        normData = []\n",
        "        for i in range(count):\n",
        "            cur_sample = []\n",
        "            for j in range(self.dim):\n",
        "                cur_sample.append(self.__normire(data[i][j], j))\n",
        "            normData.append(cur_sample)\n",
        "        return normData\n",
        "    \n",
        "    def renormalize(self, normData) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        normData : list, array\n",
        "            Нормированный набор данных.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Денормированный набор данных.\n",
        "        '''\n",
        "        count = 0\n",
        "        if type(normData) == list:\n",
        "            count = len(normData)\n",
        "        else:\n",
        "            count = normData.shape[0]\n",
        "        data = []\n",
        "        for i in range(count):\n",
        "            cur_sample = []\n",
        "            for j in range(self.dim):\n",
        "                cur_sample.append(self.__renormire(normData[i][j], j))\n",
        "            data.append(cur_sample)\n",
        "        return data\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMyXmzKvuVfg"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "#!pip install git+https://github.com/naught101/sobol_seq@v0.2.0#egg=sobol_seq\n",
        "import sobol_seq\n",
        "import time\n",
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "''' Класс генерации данных '''\n",
        "class DataGenerator():\n",
        "\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim: int\n",
        "        Размерность входных данных.\n",
        "    val_range : List[Tuple[float,float]]\n",
        "        Диапазон значений входных данных.\n",
        "    '''\n",
        "    def __init__(self, dim : int, val_range : List[Tuple[float,float]]):\n",
        "        try:\n",
        "            assert dim  == len(val_range), 'Размерность входных диапазонов не равна входной размерности!'\n",
        "            self.dim = dim\n",
        "            self.val_range = val_range\n",
        "            random.seed(int(time.time()))\n",
        "        except AssertionError as e:\n",
        "            raise AssertionError(e.args[0])\n",
        "    \n",
        "\n",
        "    def get_random(self, samples_num : int, irrelevant_var_count : int = 0, write_in_file : bool = False) -> List[List[float]]:\n",
        "        '''\n",
        "        Рандомная генерация данных.\n",
        "        Parameters\n",
        "        ----------\n",
        "        samples_num : int\n",
        "            Количество записей.\n",
        "        irrelevant_var_count : int, optional\n",
        "            Количество незначащих переменных. По умолчанию 0.\n",
        "        write_in_file : bool, optional\n",
        "            Запись в файл. По умолчанию False.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        arr = []\n",
        "        for k in range(samples_num):\n",
        "            sample = []\n",
        "            # добавляем существенные переменные\n",
        "            for i in self.val_range:\n",
        "                sample.append(random.uniform(i[0], i[1]))\n",
        "            # добавляем несущественные переменные\n",
        "            if irrelevant_var_count != 0:\n",
        "                for i in range(irrelevant_var_count):\n",
        "                    sample.append(random.uniform(0., 1.))\n",
        "            arr.append(sample)\n",
        "        if write_in_file:\n",
        "            col = [('x' + str(i+1)) for i in range(self.dim + irrelevant_var_count)]\n",
        "            df = pd.DataFrame(arr, columns=col)\n",
        "            df.to_csv(f'../../DataSet/random_{self.dim}_{samples_num}_{irrelevant_var_count}.csv')\n",
        "        return arr\n",
        "    \n",
        "\n",
        "    def get_sobol(self, samples_num : int, irrelevant_var_count : int = 0, write_in_file : bool = False) -> List[List[float]]:\n",
        "        '''\n",
        "        Генерация данных от 0 до 1 методом Sobol.\n",
        "        Parameters\n",
        "        ----------\n",
        "        samples_num : int\n",
        "            Количество записей.\n",
        "        irrelevant_var_count : int, optional\n",
        "            Количество незначащих переменных. По умолчанию 0.\n",
        "        write_in_file : bool, optional\n",
        "            Запись в файл. По умолчанию False.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        arr = sobol_seq.i4_sobol_generate(self.dim, samples_num)\n",
        "        if irrelevant_var_count != 0:\n",
        "            zeros = [[0] for i in range(irrelevant_var_count)]\n",
        "            arr = np.insert(arr, obj=self.dim, values=zeros, axis=1)\n",
        "        if write_in_file:\n",
        "            col = [('x' + str(i+1)) for i in range(self.dim + irrelevant_var_count)]\n",
        "            df = pd.DataFrame(arr, columns=col)\n",
        "            df.to_csv(f'../DataSet/sobol_{self.dim}_{samples_num}_{irrelevant_var_count}.csv')\n",
        "        return list(arr)\n",
        "    \n",
        "    \n",
        "    def get_from_file(self, filename : str) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        filename : str\n",
        "            Имя файла.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        OSError\n",
        "            Файл не найден.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        try:\n",
        "            return list(pd.read_csv(filename, index_col=0).to_numpy('float32'))\n",
        "        except OSError as e:\n",
        "            raise OSError(e.args[0])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foZwblL7uYOt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from keras.layers import Lambda\n",
        "import numpy as np\n",
        "\n",
        "''' Класс автоэнкодеров '''\n",
        "class AutoencoderClass():\n",
        "  def __init__(self, func, input_dim : int, encoding_dim : int, activations : list, enc_type : str, normalizer : Normalizer):\n",
        "    self.func = func                 # Функция обучения\n",
        "    self.batch = 0                   # Размр батча\n",
        "    self.input_dim = input_dim       # Размерность входного представления\n",
        "    self.encoding_dim = encoding_dim # Размерность кодированного представления\n",
        "    self.activations = activations   # Функции активации\n",
        "    self.enc_type = enc_type         # Тип автоэнкодера\n",
        "    self.aes_types = {'dense': self.__create_dense_ae,\n",
        "                      'deep':  self.__create_deep_dense_ae,\n",
        "                      'conv':  self.__create_deep_conv_ae,\n",
        "                      'vae':   self.__create_vae}\n",
        "    self.normalizer = normalizer\n",
        "    try:\n",
        "      # Сборка моделей\n",
        "      self.encoder, self.decoder, self.autoencoder = self.aes_types[self.enc_type]()\n",
        "      if self.aes_types != 'vae':\n",
        "        self.autoencoder.compile(optimizer = 'adam', loss = self.custom_loss, metrics=['accuracy'])\n",
        "      else:\n",
        "        self.autoencoder.compile(optimizer = 'adam', loss = self.vae_loss, metrics=['accuracy'])\n",
        "    except KeyError as e:\n",
        "      raise ValueError('Undefined unit: {}'.format(e.args[0]))\n",
        "\n",
        "  # Обучение модели\n",
        "  def fit(self, train_data, test_data, epochs : int, batch_size : int, shuffle : bool):\n",
        "    self.batch = batch_size\n",
        "    if self.enc_type != 'conv':\n",
        "      self.autoencoder.fit(train_data, train_data,\n",
        "                           epochs=epochs,\n",
        "                           batch_size=self.batch,\n",
        "                           shuffle=shuffle,\n",
        "                           validation_data=(test_data, test_data))\n",
        "    else:\n",
        "      grid_train = []\n",
        "      grid_test = []\n",
        "      for i in range(len(train_data)):\n",
        "        xx, yy = np.meshgrid(train_data[i], train_data[i])\n",
        "        grid_train.append(xx)\n",
        "\n",
        "      for i in range(len(test_data)):\n",
        "        xx, yy = np.meshgrid(test_data[i], test_data[i])\n",
        "        grid_test.append(xx)\n",
        "      \n",
        "      self.autoencoder.fit(grid_train, grid_train,\n",
        "                           epochs=epochs,\n",
        "                           batch_size=self.batch,\n",
        "                           shuffle=shuffle,\n",
        "                           validation_data=(grid_test, grid_test))\n",
        "\n",
        "  # Предсказание результата\n",
        "  def predict(self, x_vector):\n",
        "    if self.enc_type != 'conv':\n",
        "      return self.autoencoder.predict(x_vector)\n",
        "    else:\n",
        "      return self.autoencoder.predict(x_vector)[0]\n",
        "\n",
        "  # Тип автоэнкодера\n",
        "  def get_aec_type(self):\n",
        "    return self.enc_type\n",
        "\n",
        "  # Возвращает собранные модели\n",
        "  def get_models(self):\n",
        "    return self.autoencoder, self.encoder, self.decoder\n",
        "\n",
        "  # Loss функция\n",
        "  @tf.autograph.experimental.do_not_convert\n",
        "  def custom_loss(self, x_true, x_pred):\n",
        "    return K.mean(K.abs(self.func(self.normalizer.renormalize([x_pred])[0]) - self.func(self.normalizer.renormalize([x_true])[0])))\n",
        "\n",
        "  # Loss функция для вариационного автоэнкодера\n",
        "  @tf.autograph.experimental.do_not_convert\n",
        "  def vae_loss(self, x_true, x_pred):\n",
        "    x_true = K.reshape(x_true, shape=(batch_size, self.input_dim))\n",
        "    x_pred = K.reshape(x_pred, shape=(batch_size, self.input_dim))\n",
        "    loss = self.custom_loss(x_true, x_pred)\n",
        "    kl_loss = -0.5 * K.sum(1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var))\n",
        "    return loss + kl_loss\n",
        "\n",
        "  ''' Сжимающий автоэнкодер '''\n",
        "  def __create_dense_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    encoded = Dense(self.encoding_dim, activation = self.activations[0])(input_data)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape = (self.encoding_dim))\n",
        "    decoded = Dense(self.input_dim, activation = self.activations[1])(input_encoded)\n",
        "\n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name = \"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name = \"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name = \"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Глубокий автоэнкодер '''\n",
        "  def __create_deep_dense_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    x = Dense(self.encoding_dim*2, activation='relu')(input_data)\n",
        "    encoded = Dense(self.encoding_dim, activation='linear')(x)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(self.encoding_dim,))\n",
        "    x = Dense(self.encoding_dim*2, activation='relu')(input_encoded)\n",
        "    decoded = Dense(self.input_dim, activation='sigmoid')(x)\n",
        "    \n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Сверточный автоэнкодер '''\n",
        "  def __create_deep_conv_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim, self.input_dim, 1))\n",
        "    x = Conv2D(25, (2, 2), activation='relu', padding='same')(input_data)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    #x = Conv2D(32, (2, 2), activation='relu', padding='same')(x)\n",
        "    #x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    encoded = Conv2D(1, (2, 2), activation='relu', padding='same')(x)\n",
        "\n",
        "    # На этом моменте представление  (7, 7, 1) т.е. 49-размерное\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(7, 7, 1))\n",
        "    #x = Conv2D(32, (7, 7), activation='relu', padding='same')(input_encoded)\n",
        "    #x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(25, (2, 2), activation='relu', padding='same')(input_encoded)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    decoded = Conv2D(1, (2, 2), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Вариационный автоэнкодер                         '''\n",
        "  ''' Работает на основе девергенции Кульбака-Лейблера '''\n",
        "  ''' Идея: переход данных скрытого слоя к нормальному распределению'''\n",
        "  ''' Статья: https://habr.com/ru/post/484756/ '''\n",
        "  ''' Видео:  https://youtu.be/ebI3JLAcWqQ '''\n",
        "  def __create_vae(self):\n",
        "    hidden_dim = 2\n",
        "\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    x = Dense(self.encoding_dim, activation='relu')(input_data)\n",
        "    \n",
        "    self.z_mean = Dense(self.encoding_dim)(x)    # Мат ожидание\n",
        "    self.z_log_var = Dense(self.encoding_dim)(x) # Логарифм дисперсии\n",
        "    \n",
        "    # Нормальное распределение N(0, 1)\n",
        "    def noiser(args):\n",
        "      self.z_mean, self.z_log_var = args\n",
        "      N = K.random_normal(shape=(self.batch, self.encoding_dim), mean=0., stddev=1.0)\n",
        "      return K.exp(self.z_log_var / 2) * N + self.z_mean\n",
        "    \n",
        "    # Преобразование данных в нормальное распределения\n",
        "    h = Lambda(noiser, output_shape=(self.encoding_dim,))([self.z_mean, self.z_log_var])\n",
        "    \n",
        "    input_encoded = Input(shape=(self.encoding_dim,))\n",
        "    d = Dense(self.encoding_dim, activation='relu')(input_encoded)\n",
        "    decoded = Dense(self.input_dim, activation='sigmoid')(d)\n",
        "    \n",
        "    encoder = Model(input_data, h, name='encoder')\n",
        "    decoder = Model(input_encoded, decoded, name='decoder')\n",
        "    vae = Model(input_data, decoder(encoder(input_data)), name=\"vae\")\n",
        "    return encoder, decoder, vae"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJFa6Av_hMvs"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def func(x):\n",
        "  return x[0]*x[1] + x[1]*x[2] + x[2]*x[3] + x[3]*x[4] + x[4]*x[5] + x[5]*x[5] + x[6]*x[6] + x[7]*x[1]\n",
        "\n",
        "def disp_res(orig_x, orig_y, pred_x, pred_y):\n",
        "  n = len(orig_x)\n",
        "  for i in range(n):\n",
        "    print(f'Orig X: {orig_x[i]}')\n",
        "    print(f'Orig Y: {orig_y[i]}')\n",
        "    print(f'Pred X: {pred_x[i]}')\n",
        "    print(f'Pred X: {pred_y[i]}\\n')\n",
        "\n",
        "\n",
        "def compare(orig_data, pred_data):\n",
        "  # clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "  # scores_x = cross_val_score(clf, orig_data[0:10], pred_data[0:10], cv=5)\n",
        "  # scores_y = cross_val_score(clf, [func(x) for x in orig_data][0:10], [func(x) for x in pred_data][0:10], cv=5)\n",
        "  y_orig = [func(x) for x in orig_data]\n",
        "  y_pred = [func(x) for x in pred_data]\n",
        "  k = 10\n",
        "  disp_res(orig_data[0:k], y_orig[0:k], pred_data[0:k], y_pred[0:k])\n",
        "\n",
        "  x_error = mean_absolute_error(orig_data, pred_data)\n",
        "  y_error = mean_absolute_error(y_orig, y_pred)\n",
        "\n",
        "  print(f'Abs error X: {x_error:.2f}')\n",
        "  print(f'Abs error Y: {y_error:.2f}')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ndsDOjUubS-",
        "outputId": "f6db4697-ae76-44f0-9a0a-b95045f6c2a9"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  dim = 8\n",
        "  irr_dim = 0\n",
        "  data_range = [(0, 100), (0, 100), (0, 100), (0, 100), (0, 100), (0, 100), (0, 100), (0, 100)]\n",
        "  generator = DataGenerator(dim, data_range)\n",
        "  normalizer = Normalizer(dim, data_range)\n",
        "\n",
        "  n = 150000\n",
        "  sobol_data = generator.get_sobol(n, irr_dim)\n",
        "  random.shuffle(sobol_data)\n",
        "  data_train = np.array(sobol_data[0:int(n * 0.8)])\n",
        "  data_test = np.array(sobol_data[int(n * 0.8):n])\n",
        "\n",
        "  model = AutoencoderClass(func, dim + irr_dim, 5, list(['relu', 'sigmoid']), 'vae', normalizer)\n",
        "  model.fit(data_train, data_test, 15, 50, True)\n",
        "\n",
        "  rand_data = generator.get_random(100)\n",
        "  pred_data = normalizer.renormalize([model.predict(np.array(x).reshape(1,dim + irr_dim))[0] for x in normalizer.normalize(rand_data)])\n",
        "  #pred_data = normalizer.renormalize([model.predict(x.reshape(1,dim + irr_dim))[0] for x in sobol_data[0:100]])\n",
        "  #compare(normalizer.renormalize(sobol_data)[0:100], pred_data[0:100])\n",
        "  compare(rand_data, pred_data)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "2400/2400 [==============================] - 7s 2ms/step - loss: 7368.7046 - accuracy: 0.1348 - val_loss: 7245.1431 - val_accuracy: 0.1416\n",
            "Epoch 2/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 6978.0933 - accuracy: 0.1771 - val_loss: 6907.0103 - val_accuracy: 0.1925\n",
            "Epoch 3/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 6649.7617 - accuracy: 0.2351 - val_loss: 6570.6768 - val_accuracy: 0.2587\n",
            "Epoch 4/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 6376.6045 - accuracy: 0.2668 - val_loss: 6364.9302 - val_accuracy: 0.2674\n",
            "Epoch 5/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 6278.3301 - accuracy: 0.2926 - val_loss: 6244.6426 - val_accuracy: 0.3074\n",
            "Epoch 6/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 5988.8374 - accuracy: 0.3334 - val_loss: 5927.8003 - val_accuracy: 0.3446\n",
            "Epoch 7/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 5691.4551 - accuracy: 0.3545 - val_loss: 5793.6001 - val_accuracy: 0.3518\n",
            "Epoch 8/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 5604.1074 - accuracy: 0.3596 - val_loss: 5705.7017 - val_accuracy: 0.3593\n",
            "Epoch 9/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 5529.1987 - accuracy: 0.3654 - val_loss: 5516.2773 - val_accuracy: 0.3676\n",
            "Epoch 10/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 5409.5913 - accuracy: 0.3750 - val_loss: 5415.4473 - val_accuracy: 0.3774\n",
            "Epoch 11/15\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 5259.5327 - accuracy: 0.3853 - val_loss: 5277.3818 - val_accuracy: 0.3882\n",
            "Epoch 12/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 5109.3755 - accuracy: 0.3954 - val_loss: 5240.8091 - val_accuracy: 0.3900\n",
            "Epoch 13/15\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 5115.2739 - accuracy: 0.4018 - val_loss: 5089.7290 - val_accuracy: 0.4088\n",
            "Epoch 14/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 4904.7324 - accuracy: 0.4105 - val_loss: 4911.4214 - val_accuracy: 0.4081\n",
            "Epoch 15/15\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 4827.6465 - accuracy: 0.4170 - val_loss: 4829.8389 - val_accuracy: 0.4154\n",
            "Orig X: [54.823073488953746, 58.499916916885006, 29.57124570702262, 79.83037727353614, 81.63773879663022, 33.25362677024679, 69.6882231707246, 57.11910372973733]\n",
            "Orig Y: 25833.38171128933\n",
            "Pred X: [45.37864625453949, 61.33564114570618, 32.40383565425873, 84.12177562713623, 59.43152904510498, 48.373499512672424, 44.323575496673584, 60.55713891983032]\n",
            "Pred X: 23389.989124466523\n",
            "\n",
            "Orig X: [42.39916288432677, 39.72011001532728, 4.255652593882853, 76.03481748861861, 78.55349792110647, 10.29432600377036, 7.562665690005865, 75.93346026676537]\n",
            "Orig Y: 12137.420821521506\n",
            "Pred X: [54.85296845436096, 44.12720203399658, 15.150302648544312, 90.47679305076599, 44.7850376367569, 32.17734694480896, 35.459643602371216, 78.89848947525024]\n",
            "Pred X: 15727.207126458537\n",
            "\n",
            "Orig X: [11.934540406167994, 77.51094112937045, 94.97270902724748, 24.945998337197317, 14.152011169591983, 0.5416260325866284, 88.61074251865875, 53.24636698768571]\n",
            "Orig Y: 22995.704768779353\n",
            "Pred X: [58.81274938583374, 52.63419151306152, 82.79803991317749, 19.725582003593445, 51.044946908950806, 55.20036220550537, 57.51333236694336, 56.453585624694824]\n",
            "Pred X: 22237.651999519294\n",
            "\n",
            "Orig X: [98.38461594350744, 22.391387119189098, 79.854128494696, 28.76798874407497, 21.605462602472013, 59.813949947090805, 67.21651181848242, 72.95351878507422]\n",
            "Orig Y: 17931.40770984471\n",
            "Pred X: [75.31455159187317, 31.691431999206543, 79.0718674659729, 17.865443229675293, 33.66825878620148, 35.17695665359497, 48.326992988586426, 77.76603698730469]\n",
            "Pred X: 14128.659510120338\n",
            "\n",
            "Orig X: [2.4025309254676386, 40.014954448187176, 57.88031667710691, 59.305731696574114, 81.77258276715239, 17.929928286608956, 85.25389534512216, 35.56909793783396]\n",
            "Orig Y: 21173.61416436527\n",
            "Pred X: [39.26562964916229, 64.60708975791931, 50.138503313064575, 58.90759229660034, 61.21659278869629, 60.95263361930847, 55.182844400405884, 33.94879698753357]\n",
            "Pred X: 25020.816831398653\n",
            "\n",
            "Orig X: [60.04588848095983, 25.340646786112075, 2.868170105552348, 61.397858886336905, 25.74851041553864, 68.4347348703363, 63.87049797308195, 10.000070966816688]\n",
            "Orig Y: 14129.54004685322\n",
            "Pred X: [35.26884317398071, 36.63339018821716, 10.5694979429245, 56.82398080825806, 35.11618971824646, 49.05594289302826, 53.22215557098389, 12.66777515411377]\n",
            "Pred X: 11701.061198808995\n",
            "\n",
            "Orig X: [57.280672876701374, 77.67529399240433, 52.25865124922113, 74.89056680807396, 87.15234741925525, 52.783718556777956, 34.56089398701305, 70.34033340666778]\n",
            "Orig Y: 32993.575307262\n",
            "Pred X: [51.25492811203003, 71.69585824012756, 59.71142053604126, 84.3514084815979, 69.82249617576599, 50.95089077949524, 43.56551468372345, 75.16781091690063]\n",
            "Pred X: 32322.882356079397\n",
            "\n",
            "Orig X: [18.27696047984707, 70.82655972852362, 38.54322730206021, 60.135858721262515, 85.08769746300896, 11.51469813696111, 13.748356949834395, 8.717770064325613]\n",
            "Orig Y: 13377.844654593931\n",
            "Pred X: [47.558578848838806, 65.59613943099976, 43.07653307914734, 81.95594549179077, 65.13665914535522, 46.486395597457886, 42.04152226448059, 11.579453945159912]\n",
            "Pred X: 22530.038473223933\n",
            "\n",
            "Orig X: [48.37686852661627, 23.924233561695495, 42.80071469634695, 18.872076357184365, 58.35507062722128, 85.41255768718351, 47.12584959242455, 13.681477598303593]\n",
            "Orig Y: 18918.098913506827\n",
            "Pred X: [35.79065799713135, 47.95863926410675, 46.243879199028015, 19.468623399734497, 44.167545437812805, 65.0511085987091, 65.29600620269775, 14.43365216255188]\n",
            "Pred X: 17755.032021961473\n",
            "\n",
            "Orig X: [61.17141404851384, 29.7694118047109, 33.8327192102593, 16.88465872707029, 23.137341677364397, 44.43342994171795, 28.742332110030123, 94.1392231611936]\n",
            "Orig Y: 10421.129305106726\n",
            "Pred X: [58.827465772628784, 25.689244270324707, 38.43478262424469, 23.82405996322632, 25.194209814071655, 42.77614951133728, 55.02176284790039, 90.19109010696411]\n",
            "Pred X: 12266.340173096673\n",
            "\n",
            "Abs error X: 15.91\n",
            "Abs error Y: 3847.03\n"
          ]
        }
      ]
    }
  ]
}