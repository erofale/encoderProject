{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "opt_param_alg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erofale/encoderProject/blob/master/Code/Notebooks/opt_param_alg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6eGPk6quNpM"
      },
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "''' Класс нормировки данных '''\n",
        "class Normalizer():\n",
        "    \n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim : int\n",
        "        Размерность входных данных.\n",
        "    irr_dim : int\n",
        "        Количество незначащих переменных.\n",
        "    range_val_pairs : List[Tuple[float,float]]\n",
        "        Диапазон значений входных данных.\n",
        "    norm_min : float, optional\n",
        "        Нижняя граница нормированных данных (по умолчанию 0).\n",
        "    norm_max : float, optional\n",
        "        Верхняя граница нормированных данных (по умолчанию 1).\n",
        "    '''\n",
        "    def __init__(self, dim : int, irr_dim : int, range_val_pairs : List[Tuple[float,float]], norm_min : float = 0., norm_max : float = 1.):\n",
        "        self.dim = dim\n",
        "        self.irr_dim = irr_dim\n",
        "        self.range_val_pairs = range_val_pairs\n",
        "        self.range_val = [(i[1] - i[0]) for i in self.range_val_pairs]\n",
        "        self.norm_min = norm_min\n",
        "        self.norm_max = norm_max\n",
        "        self.range_norm = norm_max - norm_min\n",
        "    \n",
        "    \n",
        "    def __normire(self, entryVal : float, ind : int) -> float:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        entryVal : float\n",
        "            Входное значение для нормировки.\n",
        "        ind : int\n",
        "            Индекс элемента в массиве.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Нормированное значение.\n",
        "\n",
        "        '''\n",
        "        return self.norm_min + ((entryVal - self.range_val_pairs[ind][0]) * self.range_norm / self.range_val[ind])\n",
        "    \n",
        "    def __renormire(self, normVal : float, ind : int) -> float:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        normVal : float\n",
        "            Нормированное значение для денормировки.\n",
        "        ind : int\n",
        "            Индекс элемента в массиве.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Денормированное значение.\n",
        "        '''\n",
        "        return self.range_val_pairs[ind][0] + ((normVal - self.norm_min) / self.range_norm * self.range_val[ind])\n",
        "    \n",
        "    def normalize(self, data) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : list, array\n",
        "            Входной набор данных для нормировки.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Нормированный набор данных.\n",
        "        '''\n",
        "        count = 0\n",
        "        if type(data) == list: \n",
        "          count = len(data)\n",
        "        else:\n",
        "          count = data.shape[0]\n",
        "          if count == None:\n",
        "            count = 1\n",
        "        normData = []\n",
        "        for i in range(count):\n",
        "            cur_sample = []\n",
        "            for j in range(self.dim):\n",
        "                cur_sample.append(self.__normire(data[i][j], j))\n",
        "            for j in range(self.dim, self.dim + self.irr_dim):\n",
        "                cur_sample.append(data[i][j])\n",
        "            normData.append(cur_sample)\n",
        "        return normData\n",
        "    \n",
        "    def renormalize(self, normData) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        normData : list, array\n",
        "            Нормированный набор данных.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Денормированный набор данных.\n",
        "        '''\n",
        "        count = 0\n",
        "        if type(normData) == list: \n",
        "          count = len(normData)\n",
        "        else:\n",
        "          count = normData.shape[0]\n",
        "          if count == None:\n",
        "            count = 1\n",
        "        data = []\n",
        "        for i in range(count):\n",
        "            cur_sample = []\n",
        "            for j in range(self.dim):\n",
        "                cur_sample.append(self.__renormire(normData[i][j], j))\n",
        "            for j in range(self.dim, self.dim + self.irr_dim):\n",
        "                cur_sample.append(normData[i][j])\n",
        "            data.append(cur_sample)\n",
        "        return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMyXmzKvuVfg"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "!pip install git+https://github.com/naught101/sobol_seq@v0.2.0#egg=sobol_seq\n",
        "import sobol_seq\n",
        "import time\n",
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "''' Класс генерации данных '''\n",
        "class DataGenerator():\n",
        "\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim: int\n",
        "        Размерность входных данных.\n",
        "    val_range : List[Tuple[float,float]]\n",
        "        Диапазон значений входных данных.\n",
        "    '''\n",
        "    def __init__(self, dim : int, val_range : List[Tuple[float,float]]):\n",
        "        try:\n",
        "            assert dim  == len(val_range), 'Размерность входных диапазонов не равна входной размерности!'\n",
        "            self.dim = dim\n",
        "            self.val_range = val_range\n",
        "            random.seed(int(time.time()))\n",
        "        except AssertionError as e:\n",
        "            raise AssertionError(e.args[0])\n",
        "    \n",
        "\n",
        "    def get_random(self, samples_num : int, irrelevant_var_count : int = 0, write_in_file : bool = False) -> List[List[float]]:\n",
        "        '''\n",
        "        Рандомная генерация данных.\n",
        "        Parameters\n",
        "        ----------\n",
        "        samples_num : int\n",
        "            Количество записей.\n",
        "        irrelevant_var_count : int, optional\n",
        "            Количество незначащих переменных. По умолчанию 0.\n",
        "        write_in_file : bool, optional\n",
        "            Запись в файл. По умолчанию False.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        arr = []\n",
        "        for k in range(samples_num):\n",
        "            sample = []\n",
        "            # добавляем существенные переменные\n",
        "            for i in self.val_range:\n",
        "                sample.append(random.uniform(i[0], i[1]))\n",
        "            # добавляем несущественные переменные\n",
        "            if irrelevant_var_count != 0:\n",
        "                for i in range(irrelevant_var_count):\n",
        "                    sample.append(random.uniform(0., 1.))\n",
        "            arr.append(sample)\n",
        "        if write_in_file:\n",
        "            col = [('x' + str(i+1)) for i in range(self.dim + irrelevant_var_count)]\n",
        "            df = pd.DataFrame(arr, columns=col)\n",
        "            df.to_csv(f'../../DataSet/random_{self.dim}_{samples_num}_{irrelevant_var_count}.csv')\n",
        "        return arr\n",
        "    \n",
        "\n",
        "    def get_sobol(self, samples_num : int, irrelevant_var_count : int = 0, write_in_file : bool = False) -> List[List[float]]:\n",
        "        '''\n",
        "        Генерация данных от 0 до 1 методом Sobol.\n",
        "        Parameters\n",
        "        ----------\n",
        "        samples_num : int\n",
        "            Количество записей.\n",
        "        irrelevant_var_count : int, optional\n",
        "            Количество незначащих переменных. По умолчанию 0.\n",
        "        write_in_file : bool, optional\n",
        "            Запись в файл. По умолчанию False.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        arr = sobol_seq.i4_sobol_generate(self.dim, samples_num)\n",
        "        if irrelevant_var_count != 0:\n",
        "            zeros = [[0] for i in range(irrelevant_var_count)]\n",
        "            arr = np.insert(arr, obj=self.dim, values=zeros, axis=1)\n",
        "        if write_in_file:\n",
        "            col = [('x' + str(i+1)) for i in range(self.dim + irrelevant_var_count)]\n",
        "            df = pd.DataFrame(arr, columns=col)\n",
        "            df.to_csv(f'../DataSet/sobol_{self.dim}_{samples_num}_{irrelevant_var_count}.csv')\n",
        "        return list(arr)\n",
        "    \n",
        "    \n",
        "    def get_from_file(self, filename : str) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        filename : str\n",
        "            Имя файла.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        OSError\n",
        "            Файл не найден.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        try:\n",
        "            return list(pd.read_csv(filename, index_col=0).to_numpy('float32'))\n",
        "        except OSError as e:\n",
        "            raise OSError(e.args[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foZwblL7uYOt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from keras.layers import Lambda\n",
        "import numpy as np\n",
        "\n",
        "''' Класс автоэнкодеров '''\n",
        "class AutoencoderClass():\n",
        "  def __init__(self, func, input_dim : int, encoding_dim : int, activations : list, enc_type : str, normalizer : Normalizer):\n",
        "    self.func = func                 # Функция обучения\n",
        "    self.batch = 0                   # Размр батча\n",
        "    self.input_dim = input_dim       # Размерность входного представления\n",
        "    self.encoding_dim = encoding_dim # Размерность кодированного представления\n",
        "    self.activations = activations   # Функции активации\n",
        "    self.enc_type = enc_type         # Тип автоэнкодера\n",
        "    self.aes_types = {'dense': self.__create_dense_ae,\n",
        "                      'deep':  self.__create_deep_dense_ae,\n",
        "                      'conv':  self.__create_deep_conv_ae,\n",
        "                      'vae':   self.__create_vae}\n",
        "    self.normalizer = normalizer\n",
        "    try:\n",
        "      # Сборка моделей\n",
        "      self.encoder, self.decoder, self.autoencoder = self.aes_types[self.enc_type]()\n",
        "      if self.aes_types != 'vae':\n",
        "        self.autoencoder.compile(optimizer = 'adam', loss = self.custom_loss, metrics=['accuracy'])\n",
        "      else:\n",
        "        self.autoencoder.compile(optimizer = 'adam', loss = self.vae_loss, metrics=['accuracy'])\n",
        "    except KeyError as e:\n",
        "      raise ValueError('Undefined unit: {}'.format(e.args[0]))\n",
        "\n",
        "  # Обучение модели\n",
        "  def fit(self, train_data, test_data, epochs : int, batch_size : int, shuffle : bool):\n",
        "    self.batch = batch_size\n",
        "    if self.enc_type != 'conv':\n",
        "      self.autoencoder.fit(train_data, train_data,\n",
        "                           epochs=epochs,\n",
        "                           batch_size=self.batch,\n",
        "                           shuffle=shuffle,\n",
        "                           validation_data=(test_data, test_data))\n",
        "    else:\n",
        "      grid_train = []\n",
        "      grid_test = []\n",
        "      for i in range(len(train_data)):\n",
        "        xx, yy = np.meshgrid(train_data[i], train_data[i])\n",
        "        grid_train.append(xx)\n",
        "\n",
        "      for i in range(len(test_data)):\n",
        "        xx, yy = np.meshgrid(test_data[i], test_data[i])\n",
        "        grid_test.append(xx)\n",
        "      \n",
        "      self.autoencoder.fit(grid_train, grid_train,\n",
        "                           epochs=epochs,\n",
        "                           batch_size=self.batch,\n",
        "                           shuffle=shuffle,\n",
        "                           validation_data=(grid_test, grid_test))\n",
        "\n",
        "  # Предсказание результата\n",
        "  def predict(self, x_vector):\n",
        "    if self.enc_type != 'conv':\n",
        "      return self.autoencoder.predict(x_vector)\n",
        "    else:\n",
        "      return self.autoencoder.predict(x_vector)[0]\n",
        "\n",
        "  # Тип автоэнкодера\n",
        "  def get_aec_type(self):\n",
        "    return self.enc_type\n",
        "\n",
        "  # Возвращает собранные модели\n",
        "  def get_models(self):\n",
        "    return self.autoencoder, self.encoder, self.decoder\n",
        "\n",
        "  # Loss функция\n",
        "  @tf.autograph.experimental.do_not_convert\n",
        "  def custom_loss(self, x_true, x_pred):\n",
        "    return K.mean(K.abs(self.func(self.normalizer.renormalize(x_pred)[0]) - self.func(self.normalizer.renormalize(x_true)[0])))\n",
        "\n",
        "  # Loss функция для вариационного автоэнкодера\n",
        "  @tf.autograph.experimental.do_not_convert\n",
        "  def vae_loss(self, x_true, x_pred):\n",
        "    x_true = K.reshape(x_true, shape=(self.batch, self.input_dim))\n",
        "    x_pred = K.reshape(x_pred, shape=(self.batch, self.input_dim))\n",
        "    loss = self.custom_loss(x_true, x_pred)\n",
        "    kl_loss = -0.5 * K.sum(1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var))\n",
        "    return loss + kl_loss\n",
        "\n",
        "  ''' Сжимающий автоэнкодер '''\n",
        "  def __create_dense_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    encoded = Dense(self.encoding_dim, activation = self.activations[0])(input_data)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape = (self.encoding_dim))\n",
        "    decoded = Dense(self.input_dim, activation = self.activations[1])(input_encoded)\n",
        "\n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name = \"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name = \"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name = \"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Глубокий автоэнкодер '''\n",
        "  def __create_deep_dense_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    x = Dense(self.encoding_dim*2, activation='relu')(input_data)\n",
        "    encoded = Dense(self.encoding_dim, activation='linear')(x)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(self.encoding_dim,))\n",
        "    x = Dense(self.encoding_dim*2, activation='relu')(input_encoded)\n",
        "    decoded = Dense(self.input_dim, activation='sigmoid')(x)\n",
        "    \n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Сверточный автоэнкодер '''\n",
        "  def __create_deep_conv_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim, self.input_dim, 1))\n",
        "    x = Conv2D(25, (2, 2), activation='relu', padding='same')(input_data)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    #x = Conv2D(32, (2, 2), activation='relu', padding='same')(x)\n",
        "    #x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    encoded = Conv2D(1, (2, 2), activation='relu', padding='same')(x)\n",
        "\n",
        "    # На этом моменте представление  (7, 7, 1) т.е. 49-размерное\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(7, 7, 1))\n",
        "    #x = Conv2D(32, (7, 7), activation='relu', padding='same')(input_encoded)\n",
        "    #x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(25, (2, 2), activation='relu', padding='same')(input_encoded)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    decoded = Conv2D(1, (2, 2), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Вариационный автоэнкодер                         '''\n",
        "  ''' Работает на основе девергенции Кульбака-Лейблера '''\n",
        "  ''' Идея: переход данных скрытого слоя к нормальному распределению'''\n",
        "  ''' Статья: https://habr.com/ru/post/484756/ '''\n",
        "  ''' Видео:  https://youtu.be/ebI3JLAcWqQ '''\n",
        "  def __create_vae(self):\n",
        "    hidden_dim = 2\n",
        "\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    x = Dense(self.encoding_dim, activation='relu')(input_data)\n",
        "    \n",
        "    self.z_mean = Dense(self.encoding_dim)(x)    # Мат ожидание\n",
        "    self.z_log_var = Dense(self.encoding_dim)(x) # Логарифм дисперсии\n",
        "    \n",
        "    # Нормальное распределение N(0, 1)\n",
        "    def noiser(args):\n",
        "      self.z_mean, self.z_log_var = args\n",
        "      N = K.random_normal(shape=(self.batch, self.encoding_dim), mean=0., stddev=1.0)\n",
        "      return K.exp(self.z_log_var / 2) * N + self.z_mean\n",
        "    \n",
        "    # Преобразование данных в нормальное распределения\n",
        "    h = Lambda(noiser, output_shape=(self.encoding_dim,))([self.z_mean, self.z_log_var])\n",
        "    \n",
        "    input_encoded = Input(shape=(self.encoding_dim,))\n",
        "    d = Dense(self.encoding_dim, activation='relu')(input_encoded)\n",
        "    decoded = Dense(self.input_dim, activation='sigmoid')(d)\n",
        "    \n",
        "    encoder = Model(input_data, h, name='encoder')\n",
        "    decoder = Model(input_encoded, decoded, name='decoder')\n",
        "    vae = Model(input_data, decoder(encoder(input_data)), name=\"vae\")\n",
        "    return encoder, decoder, vae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJFa6Av_hMvs"
      },
      "source": [
        "from typing import Tuple, List\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "''' Класс функции '''\n",
        "class Function():\n",
        "    def __init__(self, func, dim : int, irr_dim : int, data_range : List[Tuple[float,float]]):\n",
        "        self.func = func\n",
        "        self.dim = dim\n",
        "        self.irr_dim = irr_dim\n",
        "        self.data_range = data_range\n",
        "        self.generator = DataGenerator(self.dim, self.data_range)\n",
        "        self.normalizer = Normalizer(self.dim, self.irr_dim, self.data_range)\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return self.func(x)\n",
        "        \n",
        "    def get_params(self):\n",
        "        return self.dim, self.irr_dim, self.generator, self.normalizer\n",
        "    \n",
        "\n",
        "''' Класс тестовых функций '''\n",
        "class TestFunctions():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def func_1(self):\n",
        "        def f(x):\n",
        "            return tf.math.pow(x[0],2) + tf.math.pow(x[1],2) + tf.math.pow(x[2],2) + tf.math.pow(x[3],2) + tf.math.pow(x[4],2) + tf.math.pow(x[5],2) + tf.pow(x[6],2) + tf.pow(x[7],2)\n",
        "        \n",
        "        data_range = [(0, 100), (0, 100), (0, 100), (0, 100), (0, 100), (0, 100),  (0, 100), (0, 100)]\n",
        "        func = Function(f, 8, 0, data_range)\n",
        "        return func\n",
        "        \n",
        "    def func_2(self):\n",
        "        def f(x):\n",
        "            return tf.math.pow(x[0],4) + 4 * tf.math.pow(x[0],3) * x[1] + 6 * tf.math.pow(x[0],2) + tf.math.pow(x[1],2) + 4 * x[0] * tf.math.pow(x[1],3) + tf.math.pow(x[1],4)\n",
        "        \n",
        "        data_range = [(0, 25), (0, 25)]\n",
        "        func = Function(f, 2, 2, data_range)\n",
        "        return func\n",
        "    \n",
        "    def func_3(self):\n",
        "        def f(x):\n",
        "            return tf.math.pow(x[0] - 100, 2) + tf.math.pow(x[1] + 3, 2) + 5 * tf.math.pow(x[2] + 10, 2)\n",
        "        \n",
        "        data_range = [(0, 100), (0, 100), (0, 100)]\n",
        "        func = Function(f, 3, 3, data_range)\n",
        "        return func\n",
        "    \n",
        "    def func_4(self):\n",
        "        def f(t):\n",
        "            def x1(t):\n",
        "                return t\n",
        "            def x2(t):\n",
        "                return tf.math.pow(tf.math.sin(t), 2)\n",
        "            def x3(t):\n",
        "                return tf.math.pow(tf.math.cos(t), 2)\n",
        "            def x4(t):\n",
        "                return tf.math.pow(t, 2)\n",
        "            def x5(t):\n",
        "                return 2 * t - 1\n",
        "            return x1(t[0]) + x2(t[0]) + x3(t[0]) + x4(t[0]) + x5(t[0])\n",
        "        \n",
        "        data_range = [(0, math.pi / 2)]\n",
        "        func = Function(f, 1, 0, data_range)\n",
        "        return func\n",
        "    \n",
        "    def func_5(self):\n",
        "        def f(t):\n",
        "            def x1(t):\n",
        "                return t\n",
        "            def x2(t):\n",
        "                return tf.math.pow(tf.math.sin(t), 2)\n",
        "            def x3(t):\n",
        "                return tf.math.pow(tf.math.cos(t), 2)\n",
        "            def x4(t):\n",
        "                return 3 * t - 5\n",
        "            def x5(t):\n",
        "                return t - 2\n",
        "            def x6(t):\n",
        "                return tf.math.pow(tf.math.sin(t), 4)\n",
        "            def x7(t):\n",
        "                return tf.math.pow(tf.math.cos(t), 4)\n",
        "            return tf.math.pow(x1(t[0]), 2) + x2(t[0]) + 3 * x3(t[0]) + x4(t[0]) + tf.math.pow(x5(t[1]), 2) + x6(t[1]) + x7(t[1])\n",
        "        \n",
        "        data_range = [(0, math.pi / 2), (0, math.pi / 2)]\n",
        "        func = Function(f, 2, 0, data_range)\n",
        "        return func\n",
        "    \n",
        "    def func_6(self):\n",
        "        def f(x):\n",
        "            return tf.math.pow(x[0] - 1, 2) + tf.math.pow(x[1], 2) + x[2] + 2 * x[3] + tf.math.pow(x[4], 3) + x[5]\n",
        "        \n",
        "        data_range = [(0, 100), (0, 100), (0, 100), (0, 100), (0, 100)]\n",
        "        func = Function(f, 6, 4, data_range)\n",
        "        return func\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UImi7dTrzn6X"
      },
      "source": [
        "!pip install smt\n",
        "from smt.applications import EGO\n",
        "from smt.sampling_methods import LHS\n",
        "import sys\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import random\n",
        "\n",
        "''' Класс подбора параметров '''\n",
        "class ParamsSelection():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def __compare(self, func : Function, orig_data, pred_data):\n",
        "         y_orig = [func(x) for x in orig_data]\n",
        "         y_pred = [func(x) for x in pred_data]\n",
        "         y_error = mean_absolute_error(y_orig, y_pred)\n",
        "         return y_error\n",
        "        \n",
        "    def brute_force(self, enc_type : str, func : Function, n : int):\n",
        "        '''\n",
        "        Полный перебор\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        enc_type : str\n",
        "            Тип автоэнкодера.\n",
        "        func : Function\n",
        "            Функция для подбора параметров.\n",
        "        n : int\n",
        "            Размер генерируемого датасета.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        hp_list : List\n",
        "            Оптимальный набор параметров.\n",
        "        error : float\n",
        "            Оптимальное значение ошибки.\n",
        "\n",
        "        '''\n",
        "        \n",
        "        h_epoch = 5\n",
        "        h_size = 1\n",
        "        h_percent = 0.1\n",
        "        dim, irr_dim, generator, normalizer = func.get_params()\n",
        "        error = sys.float_info.max\n",
        "        hp_list = list()\n",
        "        for epoch in range(5, 60, h_epoch):\n",
        "          for batch in  [2**i for i in range(4, 9)]:\n",
        "            for size in range(dim // 2, dim, h_size):\n",
        "              for percent in np.arange(0.5, 1.0, h_percent):\n",
        "                  sobol_data = generator.get_sobol(n, irr_dim)\n",
        "                  random.shuffle(sobol_data)\n",
        "                  data_train = np.array(sobol_data[0:int(n * h_percent)])\n",
        "                  data_test = np.array(sobol_data[int(n * h_percent):n])\n",
        "                  model = AutoencoderClass(func, dim + irr_dim, size, list(['relu', 'sigmoid']), 'dense', normalizer)\n",
        "                  model.fit(data_train, data_test, epoch, batch, True)\n",
        "                  rand_data = generator.get_random(100)\n",
        "                  pred_data = normalizer.renormalize([model.predict(np.array(x).reshape(1,dim + irr_dim))[0] for x in normalizer.normalize(rand_data)])\n",
        "                  cur_error = self.__compare(func, rand_data, pred_data)\n",
        "                  if cur_error < error:\n",
        "                    error = cur_error\n",
        "                    hp_list.clear()\n",
        "                    hp_list.append(epoch)\n",
        "                    hp_list.append(batch)\n",
        "                    hp_list.append(size)\n",
        "                    hp_list.append(percent)\n",
        "        return hp_list, error\n",
        "    \n",
        "    def ego(self, enc_type : str, func : Function,  n : int, ndoe : int, n_iter : int):\n",
        "        '''\n",
        "        Метод EGO - эффективная глобальная оптимизация\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        enc_type : str\n",
        "            Тип автоэнкодера.\n",
        "        func : Function\n",
        "            Функция для подбора параметров.\n",
        "        n : int\n",
        "            Размер генерируемого датасета.\n",
        "        ndoe : int\n",
        "            Количесто начальных сгенерированных точек.\n",
        "        n_iter : int\n",
        "            Максимальное количество итераций алгоритма.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        x_opt : List\n",
        "            Оптимальный набор параметров.\n",
        "        error : float\n",
        "            Оптимальное значение ошибки.\n",
        "\n",
        "        '''\n",
        "        \n",
        "        dim, irr_dim, generator, normalizer = func.get_params()\n",
        "        \n",
        "        def predict_params(x):\n",
        "            ''' \n",
        "            x[0] - число эпох\n",
        "            x[1] - батчсайз\n",
        "            x[2] - размер сжатия\n",
        "            x[3] - разбиение выборки\n",
        "            '''\n",
        "            count, n_param = x.shape\n",
        "            res = np.zeros((count,1))\n",
        "            \n",
        "            for i in range(count):\n",
        "              sobol_data = generator.get_sobol(n, irr_dim)\n",
        "              random.shuffle(sobol_data)\n",
        "              data_train = np.array(sobol_data[0:int(n * x[i][3])])\n",
        "              data_test = np.array(sobol_data[int(n * x[i][3]):n])\n",
        "              model = AutoencoderClass(func, dim + irr_dim, int(x[i][2]), list(['relu', 'sigmoid']), 'dense', normalizer)\n",
        "              model.fit(data_train, data_test, int(x[i][0]), int(x[i][1]), True)\n",
        "              rand_data = generator.get_random(100)\n",
        "              pred_data = normalizer.renormalize([model.predict(np.array(xx).reshape(1,dim + irr_dim))[0] for xx in normalizer.normalize(rand_data)])\n",
        "              res[i] = self.__compare(func, rand_data, pred_data)\n",
        "            return res\n",
        "        \n",
        "        xlimits = np.array([[5,60], [16,256], [dim//2, dim - 1], [0.5, 1.0]])\n",
        "        ndoe = 6\n",
        "        n_iter = 15\n",
        "        criterion='EI'\n",
        "        sampling = LHS(xlimits=xlimits, random_state=3)\n",
        "        xdoe = sampling(ndoe)\n",
        "        ego = EGO(n_iter=n_iter, criterion=criterion, xdoe=xdoe, xlimits=xlimits)\n",
        "        x_opt, error, _, _, _ = ego.optimize(fun=predict_params)\n",
        "        return list(x_opt), error\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwMSeLaR2nqP"
      },
      "source": [
        "from contextlib import contextmanager\n",
        "import sys, os\n",
        "\n",
        "@contextmanager\n",
        "def suppress_stdout():\n",
        "    with open(os.devnull, \"w\") as devnull:\n",
        "        old_stdout = sys.stdout\n",
        "        sys.stdout = devnull\n",
        "        try:  \n",
        "            yield\n",
        "        finally:\n",
        "            sys.stdout = old_stdout\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test = TestFunctions()\n",
        "    func = test.func_1()\n",
        "    \n",
        "    optimizer = ParamsSelection()\n",
        "    with suppress_stdout():\n",
        "        x_opt, y_err = optimizer.ego('dense', func, 60000, 1, 10)\n",
        "    \n",
        "    print(f'Opt params:\\nepochs = {int(x_opt[0])}\\nbatch = {int(x_opt[1])}\\nencoded dim = {int(x_opt[2])}\\nsample split = {x_opt[3]*100:.3f} % : {(1.0 - x_opt[3])*100:.3f} %')\n",
        "    print(f'Opt Y error: {y_err}')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}