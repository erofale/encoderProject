{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "encoder",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5HBPaOx3Ga/f3OeR+jNsK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erofale/encoderProject/blob/master/Code/encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnvlllxsbMTO"
      },
      "source": [
        "from keras.layers import Input, Dense, Flatten, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "import keras.backend as K\n",
        "from keras.layers import Lambda\n",
        "from keras.regularizers import L1L2\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrn402Lzbte9"
      },
      "source": [
        "def f(x,y):\n",
        "  return x*y/10-3\n",
        "mi=-1e13-3\n",
        "ma=1e13-3\n",
        "siz=ma-mi+1\n",
        "def g(x):\n",
        "  return (x-mi)/siz"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ioW8aNY8btF"
      },
      "source": [
        "def f(x):\n",
        "  return 2*x-1\n",
        "mi=-2e7-1\n",
        "ma=2e7\n",
        "siz=ma-mi+1\n",
        "def g(x):\n",
        "  return (x-mi)/siz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttdl3ZsLiwgC"
      },
      "source": [
        "TRAIN=60000\n",
        "TEST=10000\n",
        "siz_vec=3                        ###function size\n",
        "x_train=np.ndarray((TRAIN,siz_vec))\n",
        "x_test=np.ndarray((TEST,siz_vec))\n",
        "for i in range(TRAIN):\n",
        "  c1=random.randint(-10000000,10000000)\n",
        "  c2=random.randint(-10000000,10000000)\n",
        "  x_train[i]=(g(c1),g(c2),g(f(c1,c2)))\n",
        "for i in range(TEST):\n",
        "  c1=random.randint(-10000000,10000000)\n",
        "  c2=random.randint(-10000000,10000000)\n",
        "  x_test[i]=(g(c1),g(c2),g(f(c1,c2)))"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FebBygG1izpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba6758f-39d2-44e1-ed37-3399a7e5dc81"
      },
      "source": [
        ""
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR13Q8LNb9JH"
      },
      "source": [
        "# Сжимающий автоэнкодер\n",
        "def create_dense_ae():\n",
        "    encoding_dim = 1                                                            #размер внутреннего слоя\n",
        "\n",
        "    # Энкодер\n",
        "    input_img = Input(shape=(siz_vec))                                          #вход\n",
        "    encoded = Dense(encoding_dim, activation='relu')(input_img)                 #слой\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(encoding_dim,))                                #вход\n",
        "    flat_decoded = Dense(siz_vec, activation='sigmoid')(input_encoded)         #слой\n",
        "\n",
        "    # Модель\n",
        "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, flat_decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjpI_UA_l4xb"
      },
      "source": [
        "encoded_imgs = encoder.predict(x_test, batch_size=10)\n",
        "decoded_imgs = decoder.predict(encoded_imgs, batch_size=10)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrrW6_6InNnD",
        "outputId": "75cb88e1-4c59-439c-eaed-a2cd7cf4c651"
      },
      "source": [
        "print(decoded_imgs[0])\n",
        "print(x_test[0])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5        0.49999997 0.37180462]\n",
            "[0.49999971 0.5000002  0.38356538]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcWGfogOcPdh",
        "outputId": "571fc1d5-df89-45a8-9043-505dfd17e0f0"
      },
      "source": [
        "# Сборка и обучение обычного автоэнкодера\n",
        "encoder, decoder, autoencoder = create_dense_ae()\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0215 - val_loss: 0.0102\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0079\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0076\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0068\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0063\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0056\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0049\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0042\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0026\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 9.2018e-04\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 7.6862e-04 - val_loss: 6.1837e-04\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 5.2116e-04 - val_loss: 4.2230e-04\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 3.6494e-04 - val_loss: 3.0238e-04\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 2.6977e-04 - val_loss: 2.2954e-04\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 2.1137e-04 - val_loss: 1.8417e-04\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.7371e-04 - val_loss: 1.5384e-04\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.4754e-04 - val_loss: 1.3248e-04\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 1.2829e-04 - val_loss: 1.1654e-04\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 1.1347e-04 - val_loss: 1.0419e-04\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 1.0194e-04 - val_loss: 9.4575e-05\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 9.2831e-05 - val_loss: 8.7057e-05\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 8.5598e-05 - val_loss: 8.1085e-05\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.9776e-05 - val_loss: 7.6194e-05\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 7.5095e-05 - val_loss: 7.2096e-05\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 7.1387e-05 - val_loss: 6.8850e-05\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 6.8440e-05 - val_loss: 6.6289e-05\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 6.6078e-05 - val_loss: 6.4136e-05\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 6.4205e-05 - val_loss: 6.2509e-05\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 6.2689e-05 - val_loss: 6.1828e-05\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.1443e-05 - val_loss: 6.0201e-05\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.0484e-05 - val_loss: 5.9463e-05\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 5.9706e-05 - val_loss: 5.8735e-05\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.9118e-05 - val_loss: 5.8247e-05\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.8596e-05 - val_loss: 5.7879e-05\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 5.8210e-05 - val_loss: 5.7633e-05\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 5.7865e-05 - val_loss: 5.7399e-05\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 5.7709e-05 - val_loss: 5.7869e-05\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.7489e-05 - val_loss: 5.7027e-05\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.7351e-05 - val_loss: 5.6919e-05\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 5.7303e-05 - val_loss: 5.6812e-05\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.7122e-05 - val_loss: 5.6765e-05\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 5.7093e-05 - val_loss: 5.6905e-05\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 5.7108e-05 - val_loss: 5.6665e-05\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.6965e-05 - val_loss: 5.6935e-05\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.6951e-05 - val_loss: 5.6588e-05\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.6947e-05 - val_loss: 5.7131e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f02e699f110>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RDFcd4WcAxB"
      },
      "source": [
        "# Глубокий автоэнкодер\n",
        "def create_dense_ae():\n",
        "    # Размерность кодированного представления\n",
        "    encoding_dim = 1\n",
        "\n",
        "    # Энкодер\n",
        "    input_img = Input(shape=(2))\n",
        "    flat_img = Flatten()(input_img)\n",
        "    x = Dense(encoding_dim*2, activation='relu')(flat_img)\n",
        "    x = Dense(encoding_dim*2, activation='relu')(x)\n",
        "    encoded = Dense(encoding_dim, activation='linear')(x)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(encoding_dim,))\n",
        "    x = Dense(encoding_dim*2, activation='relu')(input_encoded)\n",
        "    x = Dense(encoding_dim*2, activation='relu')(x)\n",
        "    flat_decoded = Dense(2, activation='sigmoid')(x)\n",
        "    #decoded = Reshape((2))(flat_decoded)\n",
        "    \n",
        "    # Модели\n",
        "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, flat_decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IatbjwX3cEzB"
      },
      "source": [
        "# Сверточный автоэнкодер\n",
        "def create_deep_conv_ae():\n",
        "    input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "    x = Conv2D(128, (7, 7), activation='relu', padding='same')(input_img)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(32, (2, 2), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    encoded = Conv2D(1, (7, 7), activation='relu', padding='same')(x)\n",
        "\n",
        "    # На этом моменте представление  (7, 7, 1) т.е. 49-размерное\n",
        "\n",
        "    input_encoded = Input(shape=(7, 7, 1))\n",
        "    x = Conv2D(32, (7, 7), activation='relu', padding='same')(input_encoded)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(128, (2, 2), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    decoded = Conv2D(1, (7, 7), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Модели\n",
        "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWJ6oPWIcIQr"
      },
      "source": [
        "# Denoising модель (подавляющий шумы автоэнкодер)\n",
        "batch_size = 16\n",
        "\n",
        "def create_denoising_model(autoencoder):\n",
        "    def add_noise(x):\n",
        "        noise_factor = 0.5\n",
        "        x = x + K.random_normal(x.get_shape(), 0.5, noise_factor)\n",
        "        x = K.clip(x, 0., 1.)\n",
        "        return x\n",
        "\n",
        "    input_img  = Input(batch_shape=(batch_size, 28, 28, 1))\n",
        "    noised_img = Lambda(add_noise)(input_img)\n",
        "\n",
        "    noiser = Model(input_img, noised_img, name=\"noiser\")\n",
        "    denoiser_model = Model(input_img, autoencoder(noiser(input_img)), name=\"denoiser\")\n",
        "    return noiser, denoiser_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5NOFyRZcKVt"
      },
      "source": [
        "# Разреженный (Sparse) автоэнкодер\n",
        "def create_sparse_ae():\n",
        "    encoding_dim = 16\n",
        "    lambda_l1 = 0.00001\n",
        "    \n",
        "    # Энкодер\n",
        "    input_img = Input(shape=(28, 28, 1))\n",
        "    flat_img = Flatten()(input_img)\n",
        "    x = Dense(encoding_dim*3, activation='relu')(flat_img)\n",
        "    x = Dense(encoding_dim*2, activation='relu')(x)\n",
        "    encoded = Dense(encoding_dim, activation='linear', activity_regularizer=L1L2(lambda_l1))(x)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(encoding_dim,))\n",
        "    x = Dense(encoding_dim*2, activation='relu')(input_encoded)\n",
        "    x = Dense(encoding_dim*3, activation='relu')(x)\n",
        "    flat_decoded = Dense(28*28, activation='sigmoid')(x)\n",
        "    decoded = Reshape((28, 28, 1))(flat_decoded)\n",
        "    \n",
        "    # Модели\n",
        "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ruz3IYRNcMBW"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Отрисовка картинок \n",
        "def plot_digits(*args):\n",
        "    args = [x.squeeze() for x in args]\n",
        "    n = min([x.shape[0] for x in args])\n",
        "    \n",
        "    plt.figure(figsize=(2*n, 2*len(args)))\n",
        "    for j in range(n):\n",
        "        for i in range(len(args)):\n",
        "            ax = plt.subplot(len(args), n, i*n + j + 1)\n",
        "            plt.imshow(args[i][j])\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "6Al-IxfVcjYU",
        "outputId": "7d97f045-402e-4d3a-e3a0-b68c72c82b38"
      },
      "source": [
        "# Отрисовка оригинальных и декодированных картинок\n",
        "r = random.randint(0, 10000 - n)\n",
        "imgs = x_test[r:r+n]\n",
        "encoded_imgs = d_encoder.predict(imgs, batch_size=n)\n",
        "\n",
        "decoded_imgs = d_decoder.predict(encoded_imgs, batch_size=n)\n",
        "\n",
        "plot_digits(imgs, decoded_imgs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "B2wJqhFhcl10",
        "outputId": "a9f2ac8d-b5ed-4be3-da08-1f252ae23ce3"
      },
      "source": [
        "# Сборка и обучение свёрточного автоэнкодера\n",
        "c_encoder, c_decoder, c_autoencoder = create_deep_conv_ae()\n",
        "c_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "c_autoencoder.fit(x_train, x_train,\n",
        "                epochs=64,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/64\n",
            "235/235 [==============================] - 1452s 6s/step - loss: 0.1698 - val_loss: 0.0984\n",
            "Epoch 2/64\n",
            " 17/235 [=>............................] - ETA: 22:02 - loss: 0.1003"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ed7ba2b8d7eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 validation_data=(x_test, x_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha6yzISycnNq"
      },
      "source": [
        "# Отрисовка оригинальных и декодированных картинок\n",
        "r = random.randint(0, 10000 - n)\n",
        "imgs = x_test[r:r+n]\n",
        "encoded_imgs = с_encoder.predict(imgs, batch_size=n)\n",
        "\n",
        "decoded_imgs = с_decoder.predict(encoded_imgs, batch_size=n)\n",
        "\n",
        "plot_digits(imgs, decoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5MheQRbco4b",
        "outputId": "0ec198c8-67c0-4fad-e73d-cbbee316c405"
      },
      "source": [
        "# Сборка и обучение модели с шумами\n",
        "noiser, denoiser_model = create_denoising_model(autoencoder)\n",
        "denoiser_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "denoiser_model.fit(x_train, x_train,\n",
        "                   epochs=200,\n",
        "                   batch_size=batch_size,\n",
        "                   shuffle=True,\n",
        "                   validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1678 - val_loss: 0.1371\n",
            "Epoch 2/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1360 - val_loss: 0.1314\n",
            "Epoch 3/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1324 - val_loss: 0.1307\n",
            "Epoch 4/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1310 - val_loss: 0.1286\n",
            "Epoch 5/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1303 - val_loss: 0.1281\n",
            "Epoch 6/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1297 - val_loss: 0.1285\n",
            "Epoch 7/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1293 - val_loss: 0.1271\n",
            "Epoch 8/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1290 - val_loss: 0.1266\n",
            "Epoch 9/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1288 - val_loss: 0.1271\n",
            "Epoch 10/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1287 - val_loss: 0.1278\n",
            "Epoch 11/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1284 - val_loss: 0.1267\n",
            "Epoch 12/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1284 - val_loss: 0.1272\n",
            "Epoch 13/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1283 - val_loss: 0.1265\n",
            "Epoch 14/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1282 - val_loss: 0.1261\n",
            "Epoch 15/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1281 - val_loss: 0.1264\n",
            "Epoch 16/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1281 - val_loss: 0.1266\n",
            "Epoch 17/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1280 - val_loss: 0.1262\n",
            "Epoch 18/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1279 - val_loss: 0.1265\n",
            "Epoch 19/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1278 - val_loss: 0.1258\n",
            "Epoch 20/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1277 - val_loss: 0.1257\n",
            "Epoch 21/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1277 - val_loss: 0.1259\n",
            "Epoch 22/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1277 - val_loss: 0.1256\n",
            "Epoch 23/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1276 - val_loss: 0.1256\n",
            "Epoch 24/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1273 - val_loss: 0.1280\n",
            "Epoch 25/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1275 - val_loss: 0.1255\n",
            "Epoch 26/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1274 - val_loss: 0.1253\n",
            "Epoch 27/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1274 - val_loss: 0.1277\n",
            "Epoch 28/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1273 - val_loss: 0.1252\n",
            "Epoch 29/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1273 - val_loss: 0.1253\n",
            "Epoch 30/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1272 - val_loss: 0.1265\n",
            "Epoch 31/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1271 - val_loss: 0.1252\n",
            "Epoch 32/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1271 - val_loss: 0.1252\n",
            "Epoch 33/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1271 - val_loss: 0.1255\n",
            "Epoch 34/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1270 - val_loss: 0.1260\n",
            "Epoch 35/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1270 - val_loss: 0.1259\n",
            "Epoch 36/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1269 - val_loss: 0.1251\n",
            "Epoch 37/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1270 - val_loss: 0.1250\n",
            "Epoch 38/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1269 - val_loss: 0.1256\n",
            "Epoch 39/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1268 - val_loss: 0.1255\n",
            "Epoch 40/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1268 - val_loss: 0.1244\n",
            "Epoch 41/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1267 - val_loss: 0.1244\n",
            "Epoch 42/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1267 - val_loss: 0.1253\n",
            "Epoch 43/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1267 - val_loss: 0.1243\n",
            "Epoch 44/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1267 - val_loss: 0.1254\n",
            "Epoch 45/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1266 - val_loss: 0.1244\n",
            "Epoch 46/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1266 - val_loss: 0.1260\n",
            "Epoch 47/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1265 - val_loss: 0.1250\n",
            "Epoch 48/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1265 - val_loss: 0.1243\n",
            "Epoch 49/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1264 - val_loss: 0.1245\n",
            "Epoch 50/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1263 - val_loss: 0.1252\n",
            "Epoch 51/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1264 - val_loss: 0.1246\n",
            "Epoch 52/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1263 - val_loss: 0.1249\n",
            "Epoch 53/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1263 - val_loss: 0.1246\n",
            "Epoch 54/200\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1262 - val_loss: 0.1244\n",
            "Epoch 55/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1262 - val_loss: 0.1248\n",
            "Epoch 56/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1261 - val_loss: 0.1239\n",
            "Epoch 57/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1261 - val_loss: 0.1246\n",
            "Epoch 58/200\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1261 - val_loss: 0.1245\n",
            "Epoch 59/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1260 - val_loss: 0.1243\n",
            "Epoch 60/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1260 - val_loss: 0.1237\n",
            "Epoch 61/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1259 - val_loss: 0.1238\n",
            "Epoch 62/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1259 - val_loss: 0.1239\n",
            "Epoch 63/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1259 - val_loss: 0.1244\n",
            "Epoch 64/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1257 - val_loss: 0.1241\n",
            "Epoch 65/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1258 - val_loss: 0.1250\n",
            "Epoch 66/200\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1258 - val_loss: 0.1245\n",
            "Epoch 67/200\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1256 - val_loss: 0.1238\n",
            "Epoch 68/200\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1256 - val_loss: 0.1246\n",
            "Epoch 69/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1257 - val_loss: 0.1265\n",
            "Epoch 70/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1257 - val_loss: 0.1237\n",
            "Epoch 71/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1256 - val_loss: 0.1244\n",
            "Epoch 72/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1255 - val_loss: 0.1235\n",
            "Epoch 73/200\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1255 - val_loss: 0.1237\n",
            "Epoch 74/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1256 - val_loss: 0.1236\n",
            "Epoch 75/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1254 - val_loss: 0.1244\n",
            "Epoch 76/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1254 - val_loss: 0.1242\n",
            "Epoch 77/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1255 - val_loss: 0.1238\n",
            "Epoch 78/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1254 - val_loss: 0.1240\n",
            "Epoch 79/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1254 - val_loss: 0.1239\n",
            "Epoch 80/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1253 - val_loss: 0.1240\n",
            "Epoch 81/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1253 - val_loss: 0.1236\n",
            "Epoch 82/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1252 - val_loss: 0.1237\n",
            "Epoch 83/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1252 - val_loss: 0.1236\n",
            "Epoch 84/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1252 - val_loss: 0.1232\n",
            "Epoch 85/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1253 - val_loss: 0.1239\n",
            "Epoch 86/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1252 - val_loss: 0.1233\n",
            "Epoch 87/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1252 - val_loss: 0.1238\n",
            "Epoch 88/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1251 - val_loss: 0.1242\n",
            "Epoch 89/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1251 - val_loss: 0.1230\n",
            "Epoch 90/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1252 - val_loss: 0.1239\n",
            "Epoch 91/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1252 - val_loss: 0.1231\n",
            "Epoch 92/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1250 - val_loss: 0.1236\n",
            "Epoch 93/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1250 - val_loss: 0.1230\n",
            "Epoch 94/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1250 - val_loss: 0.1234\n",
            "Epoch 95/200\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1249 - val_loss: 0.1233\n",
            "Epoch 96/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1249 - val_loss: 0.1233\n",
            "Epoch 97/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1250 - val_loss: 0.1227\n",
            "Epoch 98/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1250 - val_loss: 0.1229\n",
            "Epoch 99/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1249 - val_loss: 0.1237\n",
            "Epoch 100/200\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1249 - val_loss: 0.1232\n",
            "Epoch 101/200\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1249 - val_loss: 0.1233\n",
            "Epoch 102/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1248 - val_loss: 0.1228\n",
            "Epoch 103/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1249 - val_loss: 0.1228\n",
            "Epoch 104/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1249 - val_loss: 0.1237\n",
            "Epoch 105/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1248 - val_loss: 0.1232\n",
            "Epoch 106/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1247 - val_loss: 0.1230\n",
            "Epoch 107/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1247 - val_loss: 0.1236\n",
            "Epoch 108/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1247 - val_loss: 0.1235\n",
            "Epoch 109/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1247 - val_loss: 0.1228\n",
            "Epoch 110/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1248 - val_loss: 0.1229\n",
            "Epoch 111/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1246 - val_loss: 0.1231\n",
            "Epoch 112/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1247 - val_loss: 0.1229\n",
            "Epoch 113/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1247 - val_loss: 0.1230\n",
            "Epoch 114/200\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1247 - val_loss: 0.1229\n",
            "Epoch 115/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1246 - val_loss: 0.1238\n",
            "Epoch 116/200\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1246 - val_loss: 0.1237\n",
            "Epoch 117/200\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1245 - val_loss: 0.1231\n",
            "Epoch 118/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1246 - val_loss: 0.1235\n",
            "Epoch 119/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1245 - val_loss: 0.1226\n",
            "Epoch 120/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1246 - val_loss: 0.1228\n",
            "Epoch 121/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1245 - val_loss: 0.1226\n",
            "Epoch 122/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1246 - val_loss: 0.1226\n",
            "Epoch 123/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1245 - val_loss: 0.1229\n",
            "Epoch 124/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1245 - val_loss: 0.1232\n",
            "Epoch 125/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1245 - val_loss: 0.1226\n",
            "Epoch 126/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1245 - val_loss: 0.1225\n",
            "Epoch 127/200\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1245 - val_loss: 0.1228\n",
            "Epoch 128/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1244 - val_loss: 0.1230\n",
            "Epoch 129/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1244 - val_loss: 0.1227\n",
            "Epoch 130/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1244 - val_loss: 0.1227\n",
            "Epoch 131/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1244 - val_loss: 0.1233\n",
            "Epoch 132/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1244 - val_loss: 0.1233\n",
            "Epoch 133/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1244 - val_loss: 0.1225\n",
            "Epoch 134/200\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1245 - val_loss: 0.1228\n",
            "Epoch 135/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1244 - val_loss: 0.1226\n",
            "Epoch 136/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1244 - val_loss: 0.1229\n",
            "Epoch 137/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1243 - val_loss: 0.1230\n",
            "Epoch 138/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1244 - val_loss: 0.1225\n",
            "Epoch 139/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1243 - val_loss: 0.1228\n",
            "Epoch 140/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1244 - val_loss: 0.1224\n",
            "Epoch 141/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1244 - val_loss: 0.1226\n",
            "Epoch 142/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1242 - val_loss: 0.1230\n",
            "Epoch 143/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1243 - val_loss: 0.1228\n",
            "Epoch 144/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1243 - val_loss: 0.1229\n",
            "Epoch 145/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1243 - val_loss: 0.1222\n",
            "Epoch 146/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1244 - val_loss: 0.1226\n",
            "Epoch 147/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1243 - val_loss: 0.1225\n",
            "Epoch 148/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1243 - val_loss: 0.1233\n",
            "Epoch 149/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1243 - val_loss: 0.1226\n",
            "Epoch 150/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1243 - val_loss: 0.1232\n",
            "Epoch 151/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1242 - val_loss: 0.1224\n",
            "Epoch 152/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1243 - val_loss: 0.1228\n",
            "Epoch 153/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1243 - val_loss: 0.1228\n",
            "Epoch 154/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1242 - val_loss: 0.1224\n",
            "Epoch 155/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1243 - val_loss: 0.1221\n",
            "Epoch 156/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1243 - val_loss: 0.1223\n",
            "Epoch 157/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1242 - val_loss: 0.1228\n",
            "Epoch 158/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1242 - val_loss: 0.1225\n",
            "Epoch 159/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1242 - val_loss: 0.1228\n",
            "Epoch 160/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1242 - val_loss: 0.1227\n",
            "Epoch 161/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1242 - val_loss: 0.1228\n",
            "Epoch 162/200\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1243 - val_loss: 0.1228\n",
            "Epoch 163/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1242 - val_loss: 0.1229\n",
            "Epoch 164/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1242 - val_loss: 0.1225\n",
            "Epoch 165/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1242 - val_loss: 0.1228\n",
            "Epoch 166/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1242 - val_loss: 0.1227\n",
            "Epoch 167/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1233\n",
            "Epoch 168/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1220\n",
            "Epoch 169/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1229\n",
            "Epoch 170/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1225\n",
            "Epoch 171/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1226\n",
            "Epoch 172/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1236\n",
            "Epoch 173/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1219\n",
            "Epoch 174/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1242 - val_loss: 0.1220\n",
            "Epoch 175/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1242 - val_loss: 0.1223\n",
            "Epoch 176/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1242 - val_loss: 0.1225\n",
            "Epoch 177/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1222\n",
            "Epoch 178/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1242 - val_loss: 0.1224\n",
            "Epoch 179/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1225\n",
            "Epoch 180/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1241 - val_loss: 0.1224\n",
            "Epoch 181/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1241 - val_loss: 0.1220\n",
            "Epoch 182/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1223\n",
            "Epoch 183/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1240 - val_loss: 0.1226\n",
            "Epoch 184/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1240 - val_loss: 0.1221\n",
            "Epoch 185/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1240 - val_loss: 0.1225\n",
            "Epoch 186/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1227\n",
            "Epoch 187/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1240 - val_loss: 0.1227\n",
            "Epoch 188/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1240 - val_loss: 0.1228\n",
            "Epoch 189/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1240 - val_loss: 0.1224\n",
            "Epoch 190/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1219\n",
            "Epoch 191/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1223\n",
            "Epoch 192/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1240 - val_loss: 0.1226\n",
            "Epoch 193/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1222\n",
            "Epoch 194/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1219\n",
            "Epoch 195/200\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1239 - val_loss: 0.1222\n",
            "Epoch 196/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1240 - val_loss: 0.1222\n",
            "Epoch 197/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1240 - val_loss: 0.1224\n",
            "Epoch 198/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1241 - val_loss: 0.1228\n",
            "Epoch 199/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1240 - val_loss: 0.1222\n",
            "Epoch 200/200\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1239 - val_loss: 0.1223\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc476461a10>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjLvVt_fcqXo"
      },
      "source": [
        "# Отрисовка оригинальных, зашумлённых и декодированных картинок\n",
        "r = random.randint(0, 10000 - n)\n",
        "imgs = x_test[r:r+n]\n",
        "noised_imgs = noiser.predict(imgs, batch_size=batch_size)\n",
        "encoded_imgs = encoder.predict(noised_imgs[r:r+n],  batch_size=n)\n",
        "decoded_imgs = decoder.predict(encoded_imgs[r:r+n], batch_size=n)\n",
        "\n",
        "plot_digits(imgs[r:r+n], noised_imgs, decoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB6VWMgucsn9"
      },
      "source": [
        "# Сборка и обучение разреженного автоэнкодера\n",
        "s_encoder, s_decoder, s_autoencoder = create_sparse_ae()\n",
        "s_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "s_autoencoder.fit(x_train, x_train,\n",
        "                epochs=400,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMaUKydFcuSB"
      },
      "source": [
        "# Отрисовка оригинальных и декодированных картинок\n",
        "r = random.randint(0, 10000 - n)\n",
        "imgs = x_test[r:r+n]\n",
        "encoded_imgs = s_encoder.predict(imgs, batch_size=n)\n",
        "\n",
        "decoded_imgs = s_decoder.predict(encoded_imgs, batch_size=n)\n",
        "\n",
        "plot_digits(imgs, decoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}