{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of enc_system.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erofale/encoderProject/blob/master/Copy_of_enc_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6eGPk6quNpM"
      },
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "''' Класс нормировки данных '''\n",
        "class Normalizer():\n",
        "    \n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim : int\n",
        "        Размерность входных данных.\n",
        "    range_val_pairs : List[Tuple[float,float]]\n",
        "        Диапазон значений входных данных.\n",
        "    norm_min : float, optional\n",
        "        Нижняя граница нормированных данных (по умолчанию 0).\n",
        "    norm_max : float, optional\n",
        "        Верхняя граница нормированных данных (по умолчанию 1).\n",
        "    '''\n",
        "    def __init__(self, dim : int, range_val_pairs : List[Tuple[float,float]], norm_min : float = 0., norm_max : float = 1.):\n",
        "        self.dim = dim\n",
        "        self.range_val_pairs = range_val_pairs\n",
        "        self.range_val = [(i[1] - i[0]) for i in self.range_val_pairs]\n",
        "        self.norm_min = norm_min\n",
        "        self.norm_max = norm_max\n",
        "        self.range_norm = norm_max - norm_min\n",
        "    \n",
        "    \n",
        "    def __normire(self, entryVal : float, ind : int) -> float:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        entryVal : float\n",
        "            Входное значение для нормировки.\n",
        "        ind : int\n",
        "            Индекс элемента в массиве.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Нормированное значение.\n",
        "\n",
        "        '''\n",
        "        return self.norm_min + ((entryVal - self.range_val_pairs[ind][0]) * self.range_norm / self.range_val[ind])\n",
        "    \n",
        "    def __renormire(self, normVal : float, ind : int) -> float:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        normVal : float\n",
        "            Нормированное значение для денормировки.\n",
        "        ind : int\n",
        "            Индекс элемента в массиве.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Денормированное значение.\n",
        "        '''\n",
        "        return self.range_val_pairs[ind][0] + ((normVal - self.norm_min) / self.range_norm * self.range_val[ind])\n",
        "    \n",
        "    def normalize(self, data) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : list, array\n",
        "            Входной набор данных для нормировки.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Нормированный набор данных.\n",
        "        '''\n",
        "        count = 0\n",
        "        if type(data) == list:\n",
        "            count = len(data)\n",
        "        else:\n",
        "            count = data.shape[0]\n",
        "        normData = []\n",
        "        for i in range(count):\n",
        "            cur_sample = []\n",
        "            for j in range(self.dim):\n",
        "                cur_sample.append(self.__normire(data[i][j], j))\n",
        "            normData.append(cur_sample)\n",
        "        return normData\n",
        "    \n",
        "    def renormalize(self, normData) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        normData : list, array\n",
        "            Нормированный набор данных.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Денормированный набор данных.\n",
        "        '''\n",
        "        count = 0\n",
        "        if type(normData) == list:\n",
        "            count = len(normData)\n",
        "        else:\n",
        "            count = normData.shape[0]\n",
        "        data = []\n",
        "        for i in range(count):\n",
        "            cur_sample = []\n",
        "            for j in range(self.dim):\n",
        "                cur_sample.append(self.__renormire(normData[i][j], j))\n",
        "            data.append(cur_sample)\n",
        "        return data\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMyXmzKvuVfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc62fd6-7223-44be-d178-f6868e097031"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "!pip install git+https://github.com/naught101/sobol_seq@v0.2.0#egg=sobol_seq\n",
        "import sobol_seq\n",
        "import time\n",
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "''' Класс генерации данных '''\n",
        "class DataGenerator():\n",
        "\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim: int\n",
        "        Размерность входных данных.\n",
        "    val_range : List[Tuple[float,float]]\n",
        "        Диапазон значений входных данных.\n",
        "    '''\n",
        "    def __init__(self, dim : int, val_range : List[Tuple[float,float]]):\n",
        "        try:\n",
        "            assert dim  == len(val_range), 'Размерность входных диапазонов не равна входной размерности!'\n",
        "            self.dim = dim\n",
        "            self.val_range = val_range\n",
        "            random.seed(int(time.time()))\n",
        "        except AssertionError as e:\n",
        "            raise AssertionError(e.args[0])\n",
        "    \n",
        "\n",
        "    def get_random(self, samples_num : int, irrelevant_var_count : int = 0, write_in_file : bool = False) -> List[List[float]]:\n",
        "        '''\n",
        "        Рандомная генерация данных.\n",
        "        Parameters\n",
        "        ----------\n",
        "        samples_num : int\n",
        "            Количество записей.\n",
        "        irrelevant_var_count : int, optional\n",
        "            Количество незначащих переменных. По умолчанию 0.\n",
        "        write_in_file : bool, optional\n",
        "            Запись в файл. По умолчанию False.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        arr = []\n",
        "        for k in range(samples_num):\n",
        "            sample = []\n",
        "            # добавляем существенные переменные\n",
        "            for i in self.val_range:\n",
        "                sample.append(random.uniform(i[0], i[1]))\n",
        "            # добавляем несущественные переменные\n",
        "            if irrelevant_var_count != 0:\n",
        "                for i in range(irrelevant_var_count):\n",
        "                    sample.append(random.uniform(0., 1.))\n",
        "            arr.append(sample)\n",
        "        if write_in_file:\n",
        "            col = [('x' + str(i+1)) for i in range(self.dim + irrelevant_var_count)]\n",
        "            df = pd.DataFrame(arr, columns=col)\n",
        "            df.to_csv(f'../../DataSet/random_{self.dim}_{samples_num}_{irrelevant_var_count}.csv')\n",
        "        return arr\n",
        "    \n",
        "\n",
        "    def get_sobol(self, samples_num : int, irrelevant_var_count : int = 0, write_in_file : bool = False) -> List[List[float]]:\n",
        "        '''\n",
        "        Генерация данных от 0 до 1 методом Sobol.\n",
        "        Parameters\n",
        "        ----------\n",
        "        samples_num : int\n",
        "            Количество записей.\n",
        "        irrelevant_var_count : int, optional\n",
        "            Количество незначащих переменных. По умолчанию 0.\n",
        "        write_in_file : bool, optional\n",
        "            Запись в файл. По умолчанию False.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        arr = sobol_seq.i4_sobol_generate(self.dim, samples_num)\n",
        "        if irrelevant_var_count != 0:\n",
        "            zeros = [[0] for i in range(irrelevant_var_count)]\n",
        "            arr = np.insert(arr, obj=self.dim, values=zeros, axis=1)\n",
        "        if write_in_file:\n",
        "            col = [('x' + str(i+1)) for i in range(self.dim + irrelevant_var_count)]\n",
        "            df = pd.DataFrame(arr, columns=col)\n",
        "            df.to_csv(f'../DataSet/sobol_{self.dim}_{samples_num}_{irrelevant_var_count}.csv')\n",
        "        return list(arr)\n",
        "    \n",
        "    \n",
        "    def get_from_file(self, filename : str) -> List[List[float]]:\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        filename : str\n",
        "            Имя файла.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        OSError\n",
        "            Файл не найден.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[List[float]]\n",
        "            Список записей.\n",
        "        '''\n",
        "        try:\n",
        "            return list(pd.read_csv(filename, index_col=0).to_numpy('float32'))\n",
        "        except OSError as e:\n",
        "            raise OSError(e.args[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sobol_seq\n",
            "  Cloning https://github.com/naught101/sobol_seq (to revision v0.2.0) to /tmp/pip-install-ulsb77a7/sobol-seq_7e9590a00072409d8ecde300a783b469\n",
            "  Running command git clone -q https://github.com/naught101/sobol_seq /tmp/pip-install-ulsb77a7/sobol-seq_7e9590a00072409d8ecde300a783b469\n",
            "  Running command git checkout -q 8f819b68f64e1fea4999f5c64b73823a019fb244\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sobol_seq) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sobol_seq) (1.19.5)\n",
            "Building wheels for collected packages: sobol-seq\n",
            "  Building wheel for sobol-seq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sobol-seq: filename=sobol_seq-0.2.0-py3-none-any.whl size=8348 sha256=014e09b8f1ca9f7f868a7f6a62a362b96ecf6ee025722e7e9c437c67451bde39\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-452u52vb/wheels/44/c1/5f/2c8f9ba733ec6fac0ee99bca0dfcbceda48f15dc32f22bb431\n",
            "Successfully built sobol-seq\n",
            "Installing collected packages: sobol-seq\n",
            "Successfully installed sobol-seq-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foZwblL7uYOt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from keras.layers import Lambda\n",
        "import numpy as np\n",
        "\n",
        "''' Класс автоэнкодеров '''\n",
        "class AutoencoderClass():\n",
        "  def __init__(self, func, input_dim : int, encoding_dim : int, activations : list, enc_type : str, normalizer : Normalizer):\n",
        "    self.func = func                 # Функция обучения\n",
        "    self.batch = 0                   # Размр батча\n",
        "    self.input_dim = input_dim       # Размерность входного представления\n",
        "    self.encoding_dim = encoding_dim # Размерность кодированного представления\n",
        "    self.activations = activations   # Функции активации\n",
        "    self.enc_type = enc_type         # Тип автоэнкодера\n",
        "    self.aes_types = {'dense': self.__create_dense_ae,\n",
        "                      'deep':  self.__create_deep_dense_ae,\n",
        "                      'conv':  self.__create_deep_conv_ae,\n",
        "                      'vae':   self.__create_vae}\n",
        "    self.normalizer = normalizer\n",
        "    try:\n",
        "      # Сборка моделей\n",
        "      self.encoder, self.decoder, self.autoencoder = self.aes_types[self.enc_type]()\n",
        "      if self.aes_types != 'vae':\n",
        "        self.autoencoder.compile(optimizer = 'adam', loss = self.custom_loss, metrics=['accuracy'])\n",
        "      else:\n",
        "        self.autoencoder.compile(optimizer = 'adam', loss = self.vae_loss, metrics=['accuracy'])\n",
        "    except KeyError as e:\n",
        "      raise ValueError('Undefined unit: {}'.format(e.args[0]))\n",
        "\n",
        "  # Обучение модели\n",
        "  def fit(self, train_data, test_data, epochs : int, batch_size : int, shuffle : bool):\n",
        "    self.batch = batch_size\n",
        "    if self.enc_type != 'conv':\n",
        "      self.autoencoder.fit(train_data, train_data,\n",
        "                           epochs=epochs,\n",
        "                           batch_size=self.batch,\n",
        "                           shuffle=shuffle,\n",
        "                           validation_data=(test_data, test_data))\n",
        "    else:\n",
        "      grid_train = []\n",
        "      grid_test = []\n",
        "      for i in range(len(train_data)):\n",
        "        xx, yy = np.meshgrid(train_data[i], train_data[i])\n",
        "        grid_train.append(xx)\n",
        "\n",
        "      for i in range(len(test_data)):\n",
        "        xx, yy = np.meshgrid(test_data[i], test_data[i])\n",
        "        grid_test.append(xx)\n",
        "      \n",
        "      self.autoencoder.fit(grid_train, grid_train,\n",
        "                           epochs=epochs,\n",
        "                           batch_size=self.batch,\n",
        "                           shuffle=shuffle,\n",
        "                           validation_data=(grid_test, grid_test))\n",
        "\n",
        "  # Предсказание результата\n",
        "  def predict(self, x_vector):\n",
        "    if self.enc_type != 'conv':\n",
        "      return self.autoencoder.predict(x_vector)\n",
        "    else:\n",
        "      return self.autoencoder.predict(x_vector)[0]\n",
        "\n",
        "  # Тип автоэнкодера\n",
        "  def get_aec_type(self):\n",
        "    return self.enc_type\n",
        "\n",
        "  # Возвращает собранные модели\n",
        "  def get_models(self):\n",
        "    return self.autoencoder, self.encoder, self.decoder\n",
        "\n",
        "  # Loss функция\n",
        "  @tf.autograph.experimental.do_not_convert\n",
        "  def custom_loss(self, x_true, x_pred):\n",
        "    return K.mean(K.abs(self.func(self.normalizer.renormalize([x_pred])[0]) - self.func(self.normalizer.renormalize([x_true])[0])))\n",
        "\n",
        "  # Loss функция для вариационного автоэнкодера\n",
        "  @tf.autograph.experimental.do_not_convert\n",
        "  def vae_loss(self, x_true, x_pred):\n",
        "    x_true = K.reshape(x_true, shape=(batch_size, self.input_dim))\n",
        "    x_pred = K.reshape(x_pred, shape=(batch_size, self.input_dim))\n",
        "    loss = self.custom_loss(x_true, x_pred)\n",
        "    kl_loss = -0.5 * K.sum(1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var))\n",
        "    return loss + kl_loss\n",
        "\n",
        "  ''' Сжимающий автоэнкодер '''\n",
        "  def __create_dense_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    encoded = Dense(self.encoding_dim, activation = self.activations[0])(input_data)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape = (self.encoding_dim))\n",
        "    decoded = Dense(self.input_dim, activation = self.activations[1])(input_encoded)\n",
        "\n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name = \"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name = \"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name = \"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Глубокий автоэнкодер '''\n",
        "  def __create_deep_dense_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    x = Dense(self.encoding_dim*2, activation='relu')(input_data)\n",
        "    encoded = Dense(self.encoding_dim, activation='linear')(x)\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(self.encoding_dim,))\n",
        "    x = Dense(self.encoding_dim*2, activation='relu')(input_encoded)\n",
        "    decoded = Dense(self.input_dim, activation='sigmoid')(x)\n",
        "    \n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Сверточный автоэнкодер '''\n",
        "  def __create_deep_conv_ae(self):\n",
        "    # Энкодер\n",
        "    input_data = Input(shape=(self.input_dim, self.input_dim, 1))\n",
        "    x = Conv2D(25, (2, 2), activation='relu', padding='same')(input_data)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    #x = Conv2D(32, (2, 2), activation='relu', padding='same')(x)\n",
        "    #x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    encoded = Conv2D(1, (2, 2), activation='relu', padding='same')(x)\n",
        "\n",
        "    # На этом моменте представление  (7, 7, 1) т.е. 49-размерное\n",
        "    \n",
        "    # Декодер\n",
        "    input_encoded = Input(shape=(7, 7, 1))\n",
        "    #x = Conv2D(32, (7, 7), activation='relu', padding='same')(input_encoded)\n",
        "    #x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(25, (2, 2), activation='relu', padding='same')(input_encoded)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    decoded = Conv2D(1, (2, 2), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Модели\n",
        "    encoder = Model(input_data, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_data, decoder(encoder(input_data)), name=\"autoencoder\")\n",
        "    return encoder, decoder, autoencoder\n",
        "\n",
        "  ''' Вариационный автоэнкодер                         '''\n",
        "  ''' Работает на основе девергенции Кульбака-Лейблера '''\n",
        "  ''' Идея: переход данных скрытого слоя к нормальному распределению'''\n",
        "  ''' Статья: https://habr.com/ru/post/484756/ '''\n",
        "  ''' Видео:  https://youtu.be/ebI3JLAcWqQ '''\n",
        "  def __create_vae(self):\n",
        "    hidden_dim = 2\n",
        "\n",
        "    input_data = Input(shape=(self.input_dim))\n",
        "    x = Dense(self.encoding_dim, activation='relu')(input_data)\n",
        "    \n",
        "    self.z_mean = Dense(self.encoding_dim)(x)    # Мат ожидание\n",
        "    self.z_log_var = Dense(self.encoding_dim)(x) # Логарифм дисперсии\n",
        "    \n",
        "    # Нормальное распределение N(0, 1)\n",
        "    def noiser(args):\n",
        "      self.z_mean, self.z_log_var = args\n",
        "      N = K.random_normal(shape=(self.batch, self.encoding_dim), mean=0., stddev=1.0)\n",
        "      return K.exp(self.z_log_var / 2) * N + self.z_mean\n",
        "    \n",
        "    # Преобразование данных в нормальное распределения\n",
        "    h = Lambda(noiser, output_shape=(self.encoding_dim,))([self.z_mean, self.z_log_var])\n",
        "    \n",
        "    input_encoded = Input(shape=(self.encoding_dim,))\n",
        "    d = Dense(self.encoding_dim, activation='relu')(input_encoded)\n",
        "    decoded = Dense(self.input_dim, activation='sigmoid')(d)\n",
        "    \n",
        "    encoder = Model(input_data, h, name='encoder')\n",
        "    decoder = Model(input_encoded, decoded, name='decoder')\n",
        "    vae = Model(input_data, decoder(encoder(input_data)), name=\"vae\")\n",
        "    return encoder, decoder, vae"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJFa6Av_hMvs"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def func(x):\n",
        "  return x[0]*x[1] + x[1]*x[2] + x[2]*x[3] + x[3]*x[4] + x[4]*x[5] + x[5]*x[5] + x[6]*x[6] + x[7]*x[1]\n",
        "\n",
        "def disp_res(orig_x, orig_y, pred_x, pred_y):\n",
        "  n = len(orig_x)\n",
        "  for i in range(n):\n",
        "    print(f'Orig X: {orig_x[i]}')\n",
        "    print(f'Orig Y: {orig_y[i]}')\n",
        "    print(f'Pred X: {pred_x[i]}')\n",
        "    print(f'Pred X: {pred_y[i]}\\n')\n",
        "\n",
        "\n",
        "def compare(orig_data, pred_data):\n",
        "  # clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "  # scores_x = cross_val_score(clf, orig_data[0:10], pred_data[0:10], cv=5)\n",
        "  # scores_y = cross_val_score(clf, [func(x) for x in orig_data][0:10], [func(x) for x in pred_data][0:10], cv=5)\n",
        "  y_orig = [func(x) for x in orig_data]\n",
        "  y_pred = [func(x) for x in pred_data]\n",
        "  k = 10\n",
        "  disp_res(orig_data[0:k], y_orig[0:k], pred_data[0:k], y_pred[0:k])\n",
        "\n",
        "  x_error = mean_absolute_error(orig_data, pred_data)\n",
        "  y_error = mean_absolute_error(y_orig, y_pred)\n",
        "\n",
        "  print(f'Abs error X: {x_error:.2f}')\n",
        "  print(f'Abs error Y: {y_error:.2f}')\n",
        "  return y_error"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DtsiTontXlf"
      },
      "source": [
        " #данные, тип автоэнкодера, шаг эпох, шаг батчей, шаг размерности, исходная размерность, размерность незначимых, шаг разбиения на выборку, количество точек\n",
        "import sys\n",
        "from numpy import arange\n",
        "def searchOpt(sobol_data ,enc_type : str, h_epoch : int, h_batch : int, h_size : int, dim : int, irr_dim : int, h_percent : float, n : int):\n",
        "  error = sys.float_info.max\n",
        "  hp_list = list()\n",
        "  for percent in arange(0.5, 1.0, h_percent):\n",
        "    for size in range(dim // 2, dim ,h_size):\n",
        "      for batch in range(50, 256, h_batch):\n",
        "        for epoch in range(5, 60, h_epoch):\n",
        "            data_train = np.array(sobol_data[0:int(n * h_percent)])\n",
        "            data_test = np.array(sobol_data[int(n * h_percent):n])\n",
        "            model = AutoencoderClass(func, dim + irr_dim, size, list(['relu', 'sigmoid']), enc_type, normalizer)\n",
        "            model.fit(data_train, data_test, epoch, batch, True)\n",
        "            rand_data = generator.get_random(100)\n",
        "            pred_data = normalizer.renormalize([model.predict(np.array(x).reshape(1,dim + irr_dim))[0] for x in normalizer.normalize(rand_data)])\n",
        "            if error > compare(rand_data, pred_data):\n",
        "              error = compare(rand_data, pred_data)\n",
        "              hp_list.clear()\n",
        "              hp_list.append(enc_type)\n",
        "              hp_list.append(epoch)\n",
        "              hp_list.append(batch)\n",
        "              hp_list.append(size)\n",
        "              hp_list.append(percent)\n",
        "  return hp_list"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ndsDOjUubS-",
        "outputId": "261e7818-7409-4b3a-e134-356b19f2afe2"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  dim = 8\n",
        "  irr_dim = 0\n",
        "  data_range = [(0, 100), (0, 100), (0, 100), (0, 100), (0, 100), (0, 100), (0, 100), (0, 100)]\n",
        "  generator = DataGenerator(dim, data_range)\n",
        "  normalizer = Normalizer(dim, data_range)\n",
        "\n",
        "  n = 150000\n",
        "  sobol_data = generator.get_sobol(n, irr_dim)\n",
        "  random.shuffle(sobol_data)\n",
        "  searchOpt(sobol_data, 'vae', 2, 16, 1, dim, irr_dim, 0.1, n)\n",
        "#  data_train = np.array(sobol_data[0:int(n * 0.8)])\n",
        "##  data_test = np.array(sobol_data[int(n * 0.8):n])\n",
        "\n",
        "  #model = AutoencoderClass(func, dim + irr_dim, 5, list(['relu', 'sigmoid']), 'vae', normalizer)\n",
        "  #model.fit(data_train, data_test, 15, 50, True)\n",
        "\n",
        "  #rand_data = generator.get_random(100)\n",
        "  #pred_data = normalizer.renormalize([model.predict(np.array(x).reshape(1,dim + irr_dim))[0] for x in normalizer.normalize(rand_data)])\n",
        "  #pred_data = normalizer.renormalize([model.predict(x.reshape(1,dim + irr_dim))[0] for x in sobol_data[0:100]])\n",
        "  #compare(normalizer.renormalize(sobol_data)[0:100], pred_data[0:100])\n",
        "  \n",
        "  #compare(rand_data, pred_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "300/300 [==============================] - 7s 20ms/step - loss: 7804.8101 - accuracy: 0.1204 - val_loss: 7266.1270 - val_accuracy: 0.1268\n",
            "Epoch 2/5\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 7159.4429 - accuracy: 0.1224 - val_loss: 7220.3340 - val_accuracy: 0.1287\n",
            "Epoch 3/5\n",
            "300/300 [==============================] - 3s 12ms/step - loss: 7202.4067 - accuracy: 0.1343 - val_loss: 7187.2871 - val_accuracy: 0.1340\n",
            "Epoch 4/5\n",
            "300/300 [==============================] - 3s 12ms/step - loss: 7168.4038 - accuracy: 0.1376 - val_loss: 7178.4009 - val_accuracy: 0.1342\n",
            "Epoch 5/5\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 7215.0449 - accuracy: 0.1371 - val_loss: 7150.6045 - val_accuracy: 0.1408\n",
            "Orig X: [7.427924462010949, 75.88204113662071, 61.094198532411305, 77.43017815954056, 81.75334519003755, 15.683068601226658, 53.250365429354815, 84.26675781820418]\n",
            "Orig Y: 27018.346279229663\n",
            "Pred X: [45.16066014766693, 56.600379943847656, 40.584224462509155, 59.865665435791016, 56.45105838775635, 58.966732025146484, 58.21220278739929, 49.663326144218445]\n",
            "Pred X: 23667.708426370133\n",
            "\n",
            "Orig X: [73.49201714652406, 80.34871371846911, 5.444267656997315, 91.3372257859167, 95.74313879608607, 22.947958878308427, 99.24013546183113, 98.19423730997238]\n",
            "Orig Y: 36046.70951713256\n",
            "Pred X: [50.909423828125, 51.0597825050354, 47.935158014297485, 52.12509036064148, 54.03297543525696, 53.132182359695435, 54.249972105026245, 49.60083365440369]\n",
            "Pred X: 21531.666979064605\n",
            "\n",
            "Orig X: [78.3471451633991, 87.5009998761772, 59.24358956303713, 23.41424153553048, 1.476657384972202, 73.49205852630789, 97.21998237737203, 88.99942631078271]\n",
            "Orig Y: 36209.914411848884\n",
            "Pred X: [50.09990930557251, 51.78448557853699, 52.61801481246948, 48.80555272102356, 51.32794976234436, 50.01309514045715, 49.4343101978302, 48.9640086889267]\n",
            "Pred X: 20440.041461253266\n",
            "\n",
            "Orig X: [33.103441156633714, 76.00909727307388, 57.24124847998954, 66.5077681188522, 41.14882653654248, 82.08127675740549, 93.45125870201475, 51.89953498956189]\n",
            "Orig Y: 36203.581366845756\n",
            "Pred X: [49.65076446533203, 52.21065878868103, 52.81102657318115, 48.820504546165466, 51.10543370246887, 49.94034767150879, 49.01943802833557, 48.88163506984711]\n",
            "Pred X: 20424.1607589319\n",
            "\n",
            "Orig X: [85.8013083196668, 30.132269256277986, 93.65462317988403, 26.377207482344854, 3.0560290689980785, 16.855540523026804, 61.06601476108524, 61.64673874520958]\n",
            "Orig Y: 13880.605945280913\n",
            "Pred X: [49.65076446533203, 52.21065878868103, 52.81102657318115, 48.820504546165466, 51.10543370246887, 49.94034767150879, 49.01943802833557, 48.88163506984711]\n",
            "Pred X: 20424.1607589319\n",
            "\n",
            "Orig X: [4.4008413599751055, 60.05123773362876, 10.75078305482271, 50.01037685273223, 78.27584680512471, 82.389819019617, 48.95174005642799, 29.355068237701175]\n",
            "Orig Y: 22758.42527495627\n",
            "Pred X: [51.232993602752686, 49.26191866397858, 43.873751163482666, 56.83693885803223, 54.79302406311035, 55.71223497390747, 58.64245891571045, 51.86835527420044]\n",
            "Pred X: 22443.625839698776\n",
            "\n",
            "Orig X: [60.939490174308084, 55.613498654174855, 32.2852754209157, 71.962083356521, 54.56631394670507, 47.19651967658689, 19.743386764660208, 21.049381243867394]\n",
            "Orig Y: 17797.85932554773\n",
            "Pred X: [47.296342253685, 54.51586842536926, 46.36262059211731, 54.65403199195862, 53.91311049461365, 54.70008850097656, 53.86037230491638, 49.290552735328674]\n",
            "Pred X: 22115.581299979607\n",
            "\n",
            "Orig X: [21.9930394376891, 20.92956268517159, 71.80147244044022, 58.91998329334041, 28.55877172142135, 80.5323064451309, 6.142484469280685, 77.5308785538646]\n",
            "Orig Y: 18322.07566073423\n",
            "Pred X: [53.54796051979065, 41.81640148162842, 34.68930721282959, 68.60093474388123, 55.25793433189392, 61.26493215560913, 69.52938437461853, 59.38383340835571]\n",
            "Pred X: 24316.548881520248\n",
            "\n",
            "Orig X: [0.03178350899144533, 63.710367488734306, 21.059913963719424, 66.18655746790172, 84.78290367646223, 39.6362218352727, 60.58387439935119, 33.04014261920081]\n",
            "Orig Y: 19056.041053973742\n",
            "Pred X: [47.31498062610626, 54.497647285461426, 46.41357064247131, 54.60805296897888, 53.89091968536377, 54.66256141662598, 53.822141885757446, 49.28731024265289]\n",
            "Pred X: 22102.095182610952\n",
            "\n",
            "Orig X: [0.28235917693792967, 11.49659681427141, 50.47729550121068, 29.760740537149154, 87.89013700503232, 72.91874121179359, 48.02708210448958, 93.23113529397908]\n",
            "Orig Y: 19805.902905610725\n",
            "Pred X: [48.231241106987, 53.642457723617554, 44.88741755485535, 55.4504930973053, 54.94655966758728, 55.58931231498718, 55.72649836540222, 49.58434700965881]\n",
            "Pred X: 22440.838943334194\n",
            "\n",
            "Abs error X: 24.87\n",
            "Abs error Y: 7624.97\n",
            "Orig X: [7.427924462010949, 75.88204113662071, 61.094198532411305, 77.43017815954056, 81.75334519003755, 15.683068601226658, 53.250365429354815, 84.26675781820418]\n",
            "Orig Y: 27018.346279229663\n",
            "Pred X: [45.16066014766693, 56.600379943847656, 40.584224462509155, 59.865665435791016, 56.45105838775635, 58.966732025146484, 58.21220278739929, 49.663326144218445]\n",
            "Pred X: 23667.708426370133\n",
            "\n",
            "Orig X: [73.49201714652406, 80.34871371846911, 5.444267656997315, 91.3372257859167, 95.74313879608607, 22.947958878308427, 99.24013546183113, 98.19423730997238]\n",
            "Orig Y: 36046.70951713256\n",
            "Pred X: [50.909423828125, 51.0597825050354, 47.935158014297485, 52.12509036064148, 54.03297543525696, 53.132182359695435, 54.249972105026245, 49.60083365440369]\n",
            "Pred X: 21531.666979064605\n",
            "\n",
            "Orig X: [78.3471451633991, 87.5009998761772, 59.24358956303713, 23.41424153553048, 1.476657384972202, 73.49205852630789, 97.21998237737203, 88.99942631078271]\n",
            "Orig Y: 36209.914411848884\n",
            "Pred X: [50.09990930557251, 51.78448557853699, 52.61801481246948, 48.80555272102356, 51.32794976234436, 50.01309514045715, 49.4343101978302, 48.9640086889267]\n",
            "Pred X: 20440.041461253266\n",
            "\n",
            "Orig X: [33.103441156633714, 76.00909727307388, 57.24124847998954, 66.5077681188522, 41.14882653654248, 82.08127675740549, 93.45125870201475, 51.89953498956189]\n",
            "Orig Y: 36203.581366845756\n",
            "Pred X: [49.65076446533203, 52.21065878868103, 52.81102657318115, 48.820504546165466, 51.10543370246887, 49.94034767150879, 49.01943802833557, 48.88163506984711]\n",
            "Pred X: 20424.1607589319\n",
            "\n",
            "Orig X: [85.8013083196668, 30.132269256277986, 93.65462317988403, 26.377207482344854, 3.0560290689980785, 16.855540523026804, 61.06601476108524, 61.64673874520958]\n",
            "Orig Y: 13880.605945280913\n",
            "Pred X: [49.65076446533203, 52.21065878868103, 52.81102657318115, 48.820504546165466, 51.10543370246887, 49.94034767150879, 49.01943802833557, 48.88163506984711]\n",
            "Pred X: 20424.1607589319\n",
            "\n",
            "Orig X: [4.4008413599751055, 60.05123773362876, 10.75078305482271, 50.01037685273223, 78.27584680512471, 82.389819019617, 48.95174005642799, 29.355068237701175]\n",
            "Orig Y: 22758.42527495627\n",
            "Pred X: [51.232993602752686, 49.26191866397858, 43.873751163482666, 56.83693885803223, 54.79302406311035, 55.71223497390747, 58.64245891571045, 51.86835527420044]\n",
            "Pred X: 22443.625839698776\n",
            "\n",
            "Orig X: [60.939490174308084, 55.613498654174855, 32.2852754209157, 71.962083356521, 54.56631394670507, 47.19651967658689, 19.743386764660208, 21.049381243867394]\n",
            "Orig Y: 17797.85932554773\n",
            "Pred X: [47.296342253685, 54.51586842536926, 46.36262059211731, 54.65403199195862, 53.91311049461365, 54.70008850097656, 53.86037230491638, 49.290552735328674]\n",
            "Pred X: 22115.581299979607\n",
            "\n",
            "Orig X: [21.9930394376891, 20.92956268517159, 71.80147244044022, 58.91998329334041, 28.55877172142135, 80.5323064451309, 6.142484469280685, 77.5308785538646]\n",
            "Orig Y: 18322.07566073423\n",
            "Pred X: [53.54796051979065, 41.81640148162842, 34.68930721282959, 68.60093474388123, 55.25793433189392, 61.26493215560913, 69.52938437461853, 59.38383340835571]\n",
            "Pred X: 24316.548881520248\n",
            "\n",
            "Orig X: [0.03178350899144533, 63.710367488734306, 21.059913963719424, 66.18655746790172, 84.78290367646223, 39.6362218352727, 60.58387439935119, 33.04014261920081]\n",
            "Orig Y: 19056.041053973742\n",
            "Pred X: [47.31498062610626, 54.497647285461426, 46.41357064247131, 54.60805296897888, 53.89091968536377, 54.66256141662598, 53.822141885757446, 49.28731024265289]\n",
            "Pred X: 22102.095182610952\n",
            "\n",
            "Orig X: [0.28235917693792967, 11.49659681427141, 50.47729550121068, 29.760740537149154, 87.89013700503232, 72.91874121179359, 48.02708210448958, 93.23113529397908]\n",
            "Orig Y: 19805.902905610725\n",
            "Pred X: [48.231241106987, 53.642457723617554, 44.88741755485535, 55.4504930973053, 54.94655966758728, 55.58931231498718, 55.72649836540222, 49.58434700965881]\n",
            "Pred X: 22440.838943334194\n",
            "\n",
            "Abs error X: 24.87\n",
            "Abs error Y: 7624.97\n",
            "Epoch 1/7\n",
            "300/300 [==============================] - 7s 20ms/step - loss: 7659.6440 - accuracy: 0.1368 - val_loss: 7322.6968 - val_accuracy: 0.1360\n",
            "Epoch 2/7\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 7362.8691 - accuracy: 0.1421 - val_loss: 7238.0303 - val_accuracy: 0.1444\n",
            "Epoch 3/7\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 7183.9795 - accuracy: 0.1603 - val_loss: 7185.1582 - val_accuracy: 0.1540\n",
            "Epoch 4/7\n",
            "300/300 [==============================] - 3s 12ms/step - loss: 7187.5688 - accuracy: 0.1665 - val_loss: 7165.4141 - val_accuracy: 0.1652\n",
            "Epoch 5/7\n",
            "300/300 [==============================] - 3s 12ms/step - loss: 7156.3994 - accuracy: 0.1759 - val_loss: 7123.3838 - val_accuracy: 0.1718\n",
            "Epoch 6/7\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 7119.7515 - accuracy: 0.1814 - val_loss: 7059.8193 - val_accuracy: 0.1789\n",
            "Epoch 7/7\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 7177.6509 - accuracy: 0.1819 - val_loss: 7050.0625 - val_accuracy: 0.1791\n",
            "Orig X: [76.61596602716652, 95.3124798904024, 36.869610893359685, 60.72718699345086, 73.92348132484224, 66.05054021791807, 21.14849971983611, 58.481893321518605]\n",
            "Orig Y: 32811.417657739396\n",
            "Pred X: [50.526612997055054, 49.66839253902435, 54.25271987915039, 50.803738832473755, 47.28882014751434, 52.38010287284851, 49.922895431518555, 49.89446699619293]\n",
            "Pred X: 20554.052817025597\n",
            "\n",
            "Orig X: [35.45138289953442, 41.3619452845605, 88.43237169159063, 12.692844425555993, 69.4937320000519, 3.364093926781375, 39.09150817622938, 58.23622514265245]\n",
            "Orig Y: 11310.614683077178\n",
            "Pred X: [48.269566893577576, 50.89293718338013, 50.175487995147705, 48.623111844062805, 50.18973350524902, 52.7182400226593, 54.787999391555786, 49.022266268730164]\n",
            "Pred X: 20811.96662855451\n",
            "\n",
            "Orig X: [2.098786484573534, 36.64605822714566, 86.54895720240259, 11.244330029155247, 69.72499395676817, 11.441365381248414, 58.68311078735001, 7.413240905942587]\n",
            "Orig Y: 9649.813782075194\n",
            "Pred X: [51.53250694274902, 49.510109424591064, 53.50193977355957, 53.33530902862549, 49.0421861410141, 53.01005244255066, 47.85248339176178, 48.8741934299469]\n",
            "Pred X: 20788.910945708485\n",
            "\n",
            "Orig X: [1.95092910295942, 13.361263792953903, 14.651218772359831, 27.58728129444481, 93.84984998605948, 59.90518741597414, 82.04628595212657, 65.00949066961364]\n",
            "Orig Y: 20026.001506017525\n",
            "Pred X: [40.30144512653351, 67.36887693405151, 31.821230053901672, 42.52316951751709, 67.70526170730591, 46.384453773498535, 61.317890882492065, 57.703697681427]\n",
            "Pred X: 22030.311692798852\n",
            "\n",
            "Orig X: [4.2124678057571145, 27.084448133030147, 16.762862886835528, 1.1913772705162917, 17.966421502514006, 16.542088305628422, 76.19244403459706, 5.726259029104308]\n",
            "Orig Y: 7140.70484643666\n",
            "Pred X: [47.99802303314209, 51.04037523269653, 49.68319535255432, 48.36066961288452, 50.53941607475281, 52.758949995040894, 55.369651317596436, 48.9172488451004]\n",
            "Pred X: 20844.984992052425\n",
            "\n",
            "Orig X: [37.42686412814583, 34.54767539328807, 98.8824386253602, 40.05737374174374, 50.20089878054921, 96.05349465339582, 41.475944950326394, 67.4510123086627]\n",
            "Orig Y: 28779.831795202503\n",
            "Pred X: [51.74238085746765, 49.47706460952759, 53.344982862472534, 53.86210083961487, 49.40868318080902, 53.141456842422485, 47.42093086242676, 48.66127967834473]\n",
            "Pred X: 20839.9684091955\n",
            "\n",
            "Orig X: [63.83729807986537, 9.925658161551954, 79.21595368913765, 60.88219443115405, 37.53326928604246, 39.69910614996941, 39.08652505693515, 82.52679866045541]\n",
            "Orig Y: 13940.792073164472\n",
            "Pred X: [52.38089561462402, 49.3764728307724, 52.866774797439575, 55.46003580093384, 50.52463412284851, 53.5412073135376, 46.109792590141296, 48.01343381404877]\n",
            "Pred X: 20999.50775237211\n",
            "\n",
            "Orig X: [81.56930422959175, 39.194395471877186, 26.302186999226997, 92.46023577093914, 32.286879781427714, 88.45248979987444, 9.17962683861231, 45.4374690989835]\n",
            "Orig Y: 22189.974353838414\n",
            "Pred X: [54.61667776107788, 49.02310073375702, 51.18305683135986, 60.964709520339966, 54.43387031555176, 54.94173765182495, 41.55743718147278, 45.74404954910278]\n",
            "Pred X: 21604.358023032368\n",
            "\n",
            "Orig X: [24.601353702932226, 12.154221216897, 71.47566855940316, 84.43259752223928, 19.375435776997417, 58.49914159660665, 87.6372516268145, 66.6923623338626]\n",
            "Orig Y: 21885.013635862622\n",
            "Pred X: [51.2104332447052, 49.560803174972534, 53.74258756637573, 52.525728940963745, 48.48014712333679, 52.8083860874176, 48.51514399051666, 49.200910329818726]\n",
            "Pred X: 20711.919458280594\n",
            "\n",
            "Orig X: [66.27412384443313, 12.676135423942492, 33.78769554451697, 28.124243457906893, 65.21708224876384, 6.2700824829384665, 76.6099779001723, 87.00992222951022]\n",
            "Orig Y: 11473.100338106657\n",
            "Pred X: [50.526612997055054, 49.66839253902435, 54.25271987915039, 50.803738832473755, 47.28882014751434, 52.38010287284851, 49.922895431518555, 49.89446699619293]\n",
            "Pred X: 20554.052817025597\n",
            "\n",
            "Abs error X: 24.27\n",
            "Abs error Y: 7208.81\n",
            "Orig X: [76.61596602716652, 95.3124798904024, 36.869610893359685, 60.72718699345086, 73.92348132484224, 66.05054021791807, 21.14849971983611, 58.481893321518605]\n",
            "Orig Y: 32811.417657739396\n",
            "Pred X: [50.526612997055054, 49.66839253902435, 54.25271987915039, 50.803738832473755, 47.28882014751434, 52.38010287284851, 49.922895431518555, 49.89446699619293]\n",
            "Pred X: 20554.052817025597\n",
            "\n",
            "Orig X: [35.45138289953442, 41.3619452845605, 88.43237169159063, 12.692844425555993, 69.4937320000519, 3.364093926781375, 39.09150817622938, 58.23622514265245]\n",
            "Orig Y: 11310.614683077178\n",
            "Pred X: [48.269566893577576, 50.89293718338013, 50.175487995147705, 48.623111844062805, 50.18973350524902, 52.7182400226593, 54.787999391555786, 49.022266268730164]\n",
            "Pred X: 20811.96662855451\n",
            "\n",
            "Orig X: [2.098786484573534, 36.64605822714566, 86.54895720240259, 11.244330029155247, 69.72499395676817, 11.441365381248414, 58.68311078735001, 7.413240905942587]\n",
            "Orig Y: 9649.813782075194\n",
            "Pred X: [51.53250694274902, 49.510109424591064, 53.50193977355957, 53.33530902862549, 49.0421861410141, 53.01005244255066, 47.85248339176178, 48.8741934299469]\n",
            "Pred X: 20788.910945708485\n",
            "\n",
            "Orig X: [1.95092910295942, 13.361263792953903, 14.651218772359831, 27.58728129444481, 93.84984998605948, 59.90518741597414, 82.04628595212657, 65.00949066961364]\n",
            "Orig Y: 20026.001506017525\n",
            "Pred X: [40.30144512653351, 67.36887693405151, 31.821230053901672, 42.52316951751709, 67.70526170730591, 46.384453773498535, 61.317890882492065, 57.703697681427]\n",
            "Pred X: 22030.311692798852\n",
            "\n",
            "Orig X: [4.2124678057571145, 27.084448133030147, 16.762862886835528, 1.1913772705162917, 17.966421502514006, 16.542088305628422, 76.19244403459706, 5.726259029104308]\n",
            "Orig Y: 7140.70484643666\n",
            "Pred X: [47.99802303314209, 51.04037523269653, 49.68319535255432, 48.36066961288452, 50.53941607475281, 52.758949995040894, 55.369651317596436, 48.9172488451004]\n",
            "Pred X: 20844.984992052425\n",
            "\n",
            "Orig X: [37.42686412814583, 34.54767539328807, 98.8824386253602, 40.05737374174374, 50.20089878054921, 96.05349465339582, 41.475944950326394, 67.4510123086627]\n",
            "Orig Y: 28779.831795202503\n",
            "Pred X: [51.74238085746765, 49.47706460952759, 53.344982862472534, 53.86210083961487, 49.40868318080902, 53.141456842422485, 47.42093086242676, 48.66127967834473]\n",
            "Pred X: 20839.9684091955\n",
            "\n",
            "Orig X: [63.83729807986537, 9.925658161551954, 79.21595368913765, 60.88219443115405, 37.53326928604246, 39.69910614996941, 39.08652505693515, 82.52679866045541]\n",
            "Orig Y: 13940.792073164472\n",
            "Pred X: [52.38089561462402, 49.3764728307724, 52.866774797439575, 55.46003580093384, 50.52463412284851, 53.5412073135376, 46.109792590141296, 48.01343381404877]\n",
            "Pred X: 20999.50775237211\n",
            "\n",
            "Orig X: [81.56930422959175, 39.194395471877186, 26.302186999226997, 92.46023577093914, 32.286879781427714, 88.45248979987444, 9.17962683861231, 45.4374690989835]\n",
            "Orig Y: 22189.974353838414\n",
            "Pred X: [54.61667776107788, 49.02310073375702, 51.18305683135986, 60.964709520339966, 54.43387031555176, 54.94173765182495, 41.55743718147278, 45.74404954910278]\n",
            "Pred X: 21604.358023032368\n",
            "\n",
            "Orig X: [24.601353702932226, 12.154221216897, 71.47566855940316, 84.43259752223928, 19.375435776997417, 58.49914159660665, 87.6372516268145, 66.6923623338626]\n",
            "Orig Y: 21885.013635862622\n",
            "Pred X: [51.2104332447052, 49.560803174972534, 53.74258756637573, 52.525728940963745, 48.48014712333679, 52.8083860874176, 48.51514399051666, 49.200910329818726]\n",
            "Pred X: 20711.919458280594\n",
            "\n",
            "Orig X: [66.27412384443313, 12.676135423942492, 33.78769554451697, 28.124243457906893, 65.21708224876384, 6.2700824829384665, 76.6099779001723, 87.00992222951022]\n",
            "Orig Y: 11473.100338106657\n",
            "Pred X: [50.526612997055054, 49.66839253902435, 54.25271987915039, 50.803738832473755, 47.28882014751434, 52.38010287284851, 49.922895431518555, 49.89446699619293]\n",
            "Pred X: 20554.052817025597\n",
            "\n",
            "Abs error X: 24.27\n",
            "Abs error Y: 7208.81\n",
            "Epoch 1/9\n",
            "300/300 [==============================] - 8s 21ms/step - loss: 7809.1885 - accuracy: 0.1321 - val_loss: 7409.6440 - val_accuracy: 0.1282\n",
            "Epoch 2/9\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 7474.5107 - accuracy: 0.1298 - val_loss: 7328.5303 - val_accuracy: 0.1294\n",
            "Epoch 3/9\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 7208.9658 - accuracy: 0.1282 - val_loss: 7265.5654 - val_accuracy: 0.1314\n",
            "Epoch 4/9\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 7287.0454 - accuracy: 0.1314 - val_loss: 7269.3608 - val_accuracy: 0.1341\n",
            "Epoch 5/9\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 7286.7393 - accuracy: 0.1263 - val_loss: 7231.6265 - val_accuracy: 0.1357\n",
            "Epoch 6/9\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 6989.4023 - accuracy: 0.1348 - val_loss: 7225.5620 - val_accuracy: 0.1371\n",
            "Epoch 7/9\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 7183.8315 - accuracy: 0.1361 - val_loss: 7207.1704 - val_accuracy: 0.1391\n",
            "Epoch 8/9\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 7619.0898 - accuracy: 0.1343 - val_loss: 7177.8774 - val_accuracy: 0.1422\n",
            "Epoch 9/9\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 7164.7529 - accuracy: 0.1448 - val_loss: 7165.3301 - val_accuracy: 0.1476\n",
            "Orig X: [82.85149542431553, 82.36562756099286, 3.3169670716827193, 84.49083378987437, 65.89935470810163, 1.6155353011406137, 45.403885158144554, 26.384243448188506]\n",
            "Orig Y: 17289.20447343959\n",
            "Pred X: [53.43337059020996, 53.02673578262329, 51.90526247024536, 47.506654262542725, 50.53226351737976, 46.168577671051025, 52.966177463531494, 47.321709990501404]\n",
            "Pred X: 20231.500058414407\n",
            "\n",
            "Orig X: [45.19469951820003, 12.685489735394185, 28.688402204999065, 3.8880912305575555, 40.292301458756526, 35.5462774033009, 50.14226934159674, 8.832934340322684]\n",
            "Orig Y: 6527.523032257075\n",
            "Pred X: [57.40354061126709, 53.76327633857727, 55.131596326828, 44.4855660200119, 48.8186776638031, 40.84303677082062, 55.767202377319336, 42.229053378105164]\n",
            "Pred X: 19716.95426827563\n",
            "\n",
            "Orig X: [90.0050926682029, 18.733420977006766, 81.45910836705914, 76.91703349904311, 47.29462279766877, 11.868894859276635, 53.51404784487036, 17.005584290768727]\n",
            "Orig Y: 16999.99777040111\n",
            "Pred X: [51.46980881690979, 52.70649790763855, 50.21654963493347, 50.097715854644775, 50.81205368041992, 48.69840145111084, 52.548450231552124, 50.30217170715332]\n",
            "Pred X: 20679.425123210352\n",
            "\n",
            "Orig X: [11.341591026339593, 25.232948272638822, 22.451873585983563, 0.1810505193357015, 10.094184424227725, 17.994620110900506, 53.83548115125548, 84.96777263638745]\n",
            "Orig Y: 6406.295034762536\n",
            "Pred X: [48.51107895374298, 52.0516037940979, 48.10383915901184, 49.34151470661163, 53.58659029006958, 53.008830547332764, 47.8572279214859, 52.84731984138489]\n",
            "Pred X: 20738.121876972098\n",
            "\n",
            "Orig X: [86.08656996551089, 77.6496386439905, 88.98103432565763, 71.61569288045013, 86.8333817682523, 48.27586351276161, 10.97415736973928, 47.537632517620324]\n",
            "Orig Y: 36519.23503987377\n",
            "Pred X: [53.189170360565186, 53.010910749435425, 51.63564085960388, 48.47663342952728, 50.2383828163147, 46.413666009902954, 53.47811579704285, 47.96173870563507]\n",
            "Pred X: 20383.748646154272\n",
            "\n",
            "Orig X: [87.34877865204865, 88.39475813786026, 64.46610946234247, 14.806924132227529, 73.59083912534936, 69.28350934906172, 84.02981823819046, 66.01122005391612]\n",
            "Orig Y: 38258.731522724986\n",
            "Pred X: [49.65754151344299, 52.386075258255005, 48.72348606586456, 51.802629232406616, 51.415252685546875, 51.10739469528198, 51.56865119934082, 52.7624249458313]\n",
            "Pred X: 21004.253425531126\n",
            "\n",
            "Orig X: [35.82352750145484, 0.765389209207179, 60.56955128573309, 69.87180953931363, 67.31987755420286, 20.544671095309987, 97.95764709679062, 58.22206334679589]\n",
            "Orig Y: 20455.05545304647\n",
            "Pred X: [60.463255643844604, 54.31995987892151, 57.69287943840027, 41.56920909881592, 47.7672815322876, 36.8521511554718, 57.449084520339966, 38.101938366889954]\n",
            "Pred X: 19290.633199824628\n",
            "\n",
            "Orig X: [35.98351920168046, 95.17782230176421, 80.37425470090837, 38.791913177876005, 47.00186545142979, 13.398100299034944, 43.981896748330975, 66.47744549162536]\n",
            "Orig Y: 25086.673456654647\n",
            "Pred X: [49.65754151344299, 52.386075258255005, 48.72348606586456, 51.802629232406616, 51.415252685546875, 51.10739469528198, 51.56865119934082, 52.7624249458313]\n",
            "Pred X: 21004.253425531126\n",
            "\n",
            "Orig X: [68.01324963274047, 36.61419396277914, 38.12911334503502, 30.873154602461995, 93.65861622548869, 34.15464202035059, 75.40842542570549, 11.191618198770136]\n",
            "Orig Y: 18416.6388009868\n",
            "Pred X: [46.3837593793869, 37.45272159576416, 51.52633190155029, 62.56470084190369, 42.23088026046753, 51.72147750854492, 54.79767322540283, 57.54067897796631]\n",
            "Pred X: 19550.086101184123\n",
            "\n",
            "Orig X: [0.3360576792493575, 18.19485098011079, 34.03990747046256, 92.60459290534571, 61.6403535266978, 38.64455657255981, 91.81164364554125, 18.99942871145549]\n",
            "Orig Y: 22136.432746628616\n",
            "Pred X: [46.196579933166504, 46.86117172241211, 45.80530226230621, 57.0979118347168, 47.60001301765442, 49.76058602333069, 51.46666765213013, 59.461408853530884]\n",
            "Pred X: 19924.534091314927\n",
            "\n",
            "Abs error X: 24.69\n",
            "Abs error Y: 7620.08\n",
            "Epoch 1/11\n",
            "300/300 [==============================] - 5s 13ms/step - loss: 8092.5190 - accuracy: 0.1315 - val_loss: 7430.8364 - val_accuracy: 0.1325\n",
            "Epoch 2/11\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 7440.7935 - accuracy: 0.1355 - val_loss: 7322.7842 - val_accuracy: 0.1339\n",
            "Epoch 3/11\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 7232.5200 - accuracy: 0.1337 - val_loss: 7262.9839 - val_accuracy: 0.1377\n",
            "Epoch 4/11\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 7323.1973 - accuracy: 0.1410 - val_loss: 7222.8057 - val_accuracy: 0.1366\n",
            "Epoch 5/11\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 7194.5571 - accuracy: 0.1407 - val_loss: 7190.8789 - val_accuracy: 0.1410\n",
            "Epoch 6/11\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 7386.3667 - accuracy: 0.1460 - val_loss: 7152.4668 - val_accuracy: 0.1560\n"
          ]
        }
      ]
    }
  ]
}